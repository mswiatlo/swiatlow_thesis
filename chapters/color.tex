%!TEX root = ../swiatlow_thesis.tex
\label{chapter:color}
\section{Motivation}

What does it mean to see color?

In terms of the color we experience on a day-to-day basis, it means that our eyes (particle detectors in their own right!) respond differently to photons with different energy (that is, different wavelengths). In terms of color at the LHC-- an aspect of the strong nuclear force now, instead of the electromagnetic-- things are much more muddled. Asymptotic freedom and the process of hadronization mean that the particles observed by the LHC detectors are not actually colored themselves-- and so unlike retinas, which measure energy directly, color at the LHC is much less direct.

The first question to ask, when considering measuring color at the LHC, is what potential \textit{measurable} effects color can have, even if the color charge itself is not directly accessible. After all-- $SU(3)_C$ singlets ($W$, $Z$, $\ell$ particles), triplets ($q$ of all types), and octets ($g$) exist: surely there must be some differences between these states. Certainly, seeing red-blue-green is not particularly useful-- there's no consequential differences between a red quark and a green quark. But, seeing the difference between an octet and a singlet might indeed be useful: gluon octets, for example, can be backgrounds to signal singlets. Additionally, the magntitude of the color charge-- in analogy to the magnitude of the electric charge-- might be useful: different types of particles have different  charges (0 for singlets, $1/3$ for triplets, $4/3$ for octets). \editnote{are these numbers correct? $C/A$}

The first evidence of color at a particle collider was observed by the JADE experiment at PETRA-- in a process very familiar to the studies of Section~\ref{jet-reconstruction:qg:validation}. At PETRA, it was observed that the third leading jet (ordered in $p$) in tri-jet events had a \textit{broader} distribution of energy (comparing the distance of particles to the center of the jet axis) than that of the leading two jets: this was interepreted as evidence for the third jet being more likely to a gluon, whie the leading two were quarks~\cite{Bartel:1983ii}. This is exactly the same effect seen by ATLAS in Section~\ref{jet-reconstruction:qg:validation}, and is directly related to the magnitude of the color charge: the larger color charge for gluons implies that they fragment ``more,'' and consequentially have a higher multiplicity and less collimated shower. This first observation from PETRA sets the stage for color will be observed in other experiments: often it is not a direct effect on the 4-momentum of a jet, but is instead a property of the jet \textit{shape}. 

A similar property, also first measured by PETRA but now explored by a variety of analyses at PEP, the Tevatron, and the LHC, is called \textit{color coherence}: this refers to the interaction of colored particles during the showering/fragmentation phase of an event, and implies that the angular distribution of jets should be somewhat different from the non-connected expectation. Many experiments have observed effects related to color coherence, at both $e^+/e^-$ and hadron-hadron colliders, in multi-jet events.~\cite{tasso,pep,PhysRevLett54270,PhysRevLett57945,PhysRevLett571398,PhysRevD.50.5562,Abbott:1997bk,Chatrchyan:2013fha}. In this type of analysis, color is sometimes measured with jet shapes, and sometimes indirectly via the push/pull of the jet axis away/towards some other jet.

% look into these papers
% bah compiling errors
Colliders operating above the $W/Z$ mass scale can produce the vector bosons, and as these are color singlets, they provide an interesting testing ground for the measurement of color. These can be a testground for further color coherence studies, as studied by the Tevatron by measuring the calorimeter activity around leptonic $W$'s and jets~\cite{Abbott:1999cu}.  L3 and DELPHI, in turn, studied the energy between $W$ bosons in $WW$ events, comparing pairs of jets from the same or different $W$, and observed that different color flow models predicted different behavior, in a process referred to as \textit{color reconnection}~\cite{Achard:2003pe,Abdallah:2006uq}. In these studies, $W$ bosons were used as test samples to study color, usually by looking outside of the jet for additional radiation: color was visible not as a property of the jet, but of the environment surrounding it.

Most of these measurements have been sensitive to the presence of color-- indeed, the seminal JADE measurement is even principle to the magntitude of the color charge-- but most of them are used to constrain color \textit{models}, and not determine the actual color properties of objects. That is to say, these measurements all help tune MC generators and shower models to more accurately reproduce the effects of hadronization and the residual effects of color, but none of them have measured the actual color representation of the $W$, for example. While it is clear from leptonic helicity measurements and $W$+jets production cross-sections that the $W$-boson is a color singlet, the hadronic decays of a $W$ have not been used to \textit{directly} measure the color type: the most direct way of \textit{seeing color} at colliders has not been performed.

Figure~\ref{fig:detector:schematic} gives an example of the color flow in the SM on the left hand side: this blue line connecting the $W$-daughter quarks is the color connection between the two jets, and is determined by the color type of the $W$: because it is a singlet, it cannot carry a color line itself, and so colored objects decaying from it must be connected (via blue/anti-blue, for example). On the right side is an example of a hypothetical alternative model, where the $W$ acts as a color octet: then, it is able to carry \textit{two} colors, and the $W$-daughter quarks do not share a color connection. The effect for this connecting color line is often referred to as \textit{color flow}. Does the blue color line in this figure exist? How can we tell?

%%%%%%%%%%%%%%%%

\begin{figure}
\centering
\includegraphics[width=0.7\textwidth]{paper/schematic.pdf}
\label{fig:color:motivation:schematic}
\caption{An example of the color flow in SM $t\bar{t}$ events on the left, and a hypothetical exotic model where the $W$ is an octet on the right.}
\end{figure}

%%%%%%%%%%%%%%%%  

This question is not just academic: telling the difference between a singlet and an octet can already be useful in LHC searches. For example, the Higgs boson has not yet been observed in its decay to $b$-quarks: as a singlet, it should have a different color flow from that of the main gluon backgrounds. Likewise, if a new particle is discovered in a dijet resonance, it will be immediately important to characterize its color representation: measuring the color flow, in a similar way to the schematic of Figure~\ref{fig:detector:schematic}, will be critical. 

\section{The Pull Angle}

What we have learned so far from previous color measurements is that two basic categories of information are useful in seeing color related effects:
%
\begin{enumerate}
\item Energy distributions inside, or surrounding, jets
\item Orientation of jet axes, and angular kinematics 
\end{enumerate}
%
One recently developed variable, the \textit{jet pull}, combines both of these types of information~\cite{Gallicchio:2010sw}. The variable composes a vector of a \pt and radial distance weighted sum over constituents of a jet and determines the oriention of this vector in relation to other jets, thereby combining the structural information about the jet with the broader context of the event (in a strategy sometimes referred to as jet superstructure). The D0 and CMS collaborations, as well as theorists, have used this variable as a part of multivariate analyses to improve sensitivity to Higgs decays to b-quarks already.~\cite{D0higgs,CMShiggspap,CMShiggspap2}. D0 also attempted a measurement of the color flow using the pull in top quark decays, comparing reconstructed data events to templates of the pull composed using singlet and octet $W$-boson models; the result, however, was strongly statistically limited and not able to distinguish.

The first step in measuring color flow with pull is to construct for a jet its \textit{pull vector}, defined as:
%
\begin{align}
\vec{v} = \sum_{i\in J} \frac{p_T^i |r_i|}{p_T^{J}}\vec{r}_i,
\end{align}
%
where $i$ iterates over elements (topo-clusters or tracks or truth particles) associated to some jet $J$, $\vec{r}_i = (\Delta y_i,\Delta\phi_i)$ (i.e. the vector composed of the difference in rapidity and azimuthal angle between the element and the jet axis). The pull vector encodes the substructure information related to the color flow of the jet: the vector points in the direction that the jet is \textit{leaning} in some sense. By itself, this information is not particularly interesting; what makes it useful is its relation to other jets. Given a pull vector composed for a jet $J_1$, the \textit{jet pull angle} $\theta_P(J_1, J_2)$is the opening angle between $\vec{v}_1$ and a jet $J_2$ in $(\Delta y,\Delta\phi)$ space~\cite{Gallicchio:2010sw}. Figure~\ref{fig:color:motivation:pull} is a sketch which demonstrates the various components of this variable: $J_1$ sits at the origin of the $(\Delta y,\Delta\phi)$ coordinate system, and its constituents (the small circles) are used to construct the pull vector $\vec{v}$; the vector between $J_1$ and $J_2$ is also drawn, and the angle between these two vectors is called $\theta_P$, the observable of interest. This schematic also points out that there are two ways for a constituent to contribute strongly to the pull vector: either it has large $\pt$ or a large $r_i$, or both. In a color connected pair of jets-- that is, a pair of jets with a color line connecting them as in the left of Figure~\ref{fig:detector:schematic}-- it is expected that the jets should lean \textit{towards each other}: their energy should be oriented between them, and the pull angle should tend to 0. On the other hand, un-connected jets-- such as the right side of Figure~\ref{fig:detector:schematic}-- should have no preferred orientation, and so the pull angle is expected to be essentially isotropically distributed. Note that while in principle $\theta_P$ ranges from $-\pi$ to $\pi$, the distribution should  be symmetric, and so in all of the following analysis we define $\theta_P$ as the absolute value of the pull angle.




\begin{figure}[h!]
 \centering
		\begin{tikzpicture}[line width=1.5 pt, scale=1.5]
			%Set up the axes.
			\draw[->] (0,0) -- (3,0);
			\draw[->] (0,0) -- (0,3);
			\node at (3.2,-0.3) {$\Delta y=y-y_{J_1}$};
			\node at (-0.1,3.3) {$\Delta \phi=\phi-\phi_{J_1}$};				
			
			%Draw the first jet.
			%{\color{red} \draw[->] (0,0) -- (2,2);}
			{\color{black} \node at (2,2.3) {$J_2$};}
			%\node [rotate=40] at (1,1.6) {\scriptsize $\text{Pull (vector)}(J_1)$};	
			
			\node [rotate=0] at (2.1,0.85) {\scriptsize Legend};
			\node [rotate=0] at (2.3,0.6) {\scriptsize $\text{Pull (vector)}(J_1)$};
			\node [rotate=0] at (1.97,0.4) {\scriptsize $\theta_P$   Pull Angle};
			{\color{black} \draw[dotted,->] (1.4,0.6) -- (1.6,0.6);}	
			\node [rotate=0] at (3.2,0.2) {\scriptsize Constituent of $J_1$ (size weighted by $p_T$)};
			\fill [black, ultra thick] (1.5,.2) circle [radius=0.03];
			
			%Draw the second jet.
			%{\color{red} \draw[->] (0,0) -- (1,-1);}
			{\color{black} \node at (0.3,-0.5) {$J_1$};}
			
			%Draw the line connecting the two jets.
			\draw[->] (0,0) -- (2,2);				
			
			{\color{black} \draw[dotted,->] (0,0) -- (0.2,1.2);}		
			%\fill[black, ultra thick] (0,0) circle [radius=0.07];
			%\fill [black, ultra thick] (2,2) circle [radius=0.07];
			\draw [black, ultra thick] (0,0) circle [radius=0.8];
			\draw [black, ultra thick] (2,2) circle [radius=0.8];
			
			\fill [black, ultra thick] (.3,.4) circle [radius=0.03];
			\fill [black, ultra thick] (-0.1,.5) circle [radius=0.04];
			\fill [black, ultra thick] (0.2,.6) circle [radius=0.03];
			\fill [black, ultra thick] (0.05,.7) circle [radius=0.04];
			\fill [black, ultra thick] (-0.15,.65) circle [radius=0.03];
			\fill [black, ultra thick] (-0.1,0) circle [radius=0.03];
			\fill [black, ultra thick] (0.1,-0.1) circle [radius=0.05];
			\fill [black, ultra thick] (-0.2,-0.2) circle [radius=0.08];

			%\fill [black, ultra thick] (-0.1,0.32) circle [radius=0.035];
                        %\draw[densely dashed, ->] (0,0) -- (-0.1,0.32);
                        %\node at (-0.155,0.145) {\scriptsize $\vec{r}_i$};
			
			%actually draw the first jet again now, toget it on top
			%{\color{red} \draw[->] (0,0) -- (2,2);}

			%Add some labels.	
			%\node at (4.5,4.5) {The {\color{green!50!black} pull vector} naturally};
			%\node at (4.5,3.5) { lives in $(\Delta y,\Delta\phi)$ space.};
			
			\draw[bend left]  (0.2,1.2) to (0.84,0.84);
			\node at (0.65,1.3) {\Large $\theta_P$};
			
			%\node at (5,-1) { \huge $\theta_P$ = Pull Angle};
							
		\end{tikzpicture}
\caption{A diagram displaying the construction of the jet pull angle for a pair of jets.}
 \label{fig:color:motivation:pull}
\end{figure}






The following chapter discusses a new ATLAS measurement (as yet unpublished) which not only measures the color flow using the jet pull, but also unfolds the data to particle level. Our goal is to demonstrate that we can ``see'' the blue color line of Figure~\ref{fig:detector:schematic}, but also to measure the energy distributions inside of jets in a context where these distributions are sensitive to color effects, in order to improve the modeling of such effects in MC simulation. Moreover, while 4-vector based measurements of color connection effects in multi-jet events have been performed at the LHC~\cite{Chatrchyan:2013fha}, there have been no measurements yet of the actual jet energy distributions which the pull angle tells us about. By demonstrating that we can tell the difference between singlets and octets, we can motivate the use of jet pull to search for the Higgs or characterize new particles; by measuring the distribution of the jet pull angle we can present to theorists the first measurement unfolded energy flow measurement at a hadron collider at $\sqrt{s} = 8$~TeV.


\section{Reconstructing Color}

\subsection{Defining the Analysis}

Following the example of the D0 analysis~\cite{Abazov:2011vh}, the measurement we perform uses $t\bar{t}$ events as Figure~\ref{fig:detector:schematic} suggests. We employ a semi-leptonic selection, where one of the $W$'s in the event decays leptonically, to select a very pure sample of top quarks: with this topology, we are able to obtain a $>90\%$ pure top sample. The leptonic $W$ acts essentially as a tag for the event, and we can then study the properties of the hadronically decaying $W$.

To compare the singlet $W$-- generated using normal \PowPythia $t\bar{t}$ samples-- to an octet $W$, we need to generate a simulation of the octet. While it is possible to compose a full BSM model which includes octet $W$'s and generate MC in this way, this is slightly non-optimal: observables just as the jet \pt and angles will potentially change due to the different particle content, while we wish to assess \textit{only} the power of color flow via the substructure. The most straightforward way to do this is to take the \textit{same events} used to generate the nominal singlets and to create new events with an inverted color structure, as displayed in Figure~\ref{fig:color:reconstructing:defining:flip}. These events have their color structure flipped at the Matrix Element level, before showering and hadronization. Once the flip is performed, showering and hadronization are run as normal-- except now reflecting the different color structure. The advantage of this scheme is that the \pt and angular distributions of jets should be exactly the same as the nominal sample, except for the color flow effects: this is as fair a comparison as we can make.


\begin{figure}[h!]
\begin{center}
\begingroup
    \fontsize{6pt}{6pt}\selectfont
\begin{Verbatim}[commandchars=\\\{\},codes={\catcode`$=3\catcode`^=7\catcode`_=8}]
 --------  PYTHIA Event Listing  (hard process)  -----------------------------------------------------------------------------------
 
    no        id   name            status     mothers   daughters     colors      px        py        pz             
     0        90   (system)           -11     0     0     0     0     0     0      0.000      0.000      0.000   8000.000  
     1      2212   (p+)               -12     0     0     3     0     0     0      0.000      0.000   4000.000   4000.000     
     2      2212   (p+)               -12     0     0     4     0     0     0      0.000      0.000  -4000.000   4000.000     
     3        21   (g)                -21     1     0     5     8  \color{green!80!black} 504  \color{blue} 503   \color{black}   0.000      0.000     94.198     94.198    
     4        21   (g)                -21     2     0     5     8  \color{yellow!80!black} 501  \color{green!80!black} 504 \color{black}     0.000      0.000   -466.748    466.748     
     5         6   (t)                -22     3     4     9    10  \color{yellow!80!black} 501 \color{black}    0     81.617    -59.344   -265.703    333.045    
     6        -5   bbar                23     3     4     0     0     0 \color{blue}  503   \color{black}  -0.916    -37.444    -61.245     71.944   
     7         3   s                   23     3     4     0     0   \color{red}502 \color{black}    0    -54.108     10.412     -0.850     55.107      
     8        -4   cbar                23     3     4     0     0     0   \color{red}502\color{black}    -26.593     86.377    -44.751    100.851     
     9        24   (W+)               -22     5     0    11    12     0     0     86.539    -59.228    -98.855    166.058    
    10         5   b                   23     5     0     0     0  \color{yellow!80!black} 501 \color{black}    0     -4.922     -0.116   -166.849    166.988     
    11       -13   mu+                 23     9     0     0     0     0     0     33.200      0.577      6.352     33.807     
    12        14   nu mu               23     9     0     0     0     0     0     53.339    -59.805   -105.207    132.250      
                                   Charge sum:  0.000           Momentum sum:     -0.000      0.000   -372.550    560.947   

 --------  PYTHIA Event Listing  (hard process)  -----------------------------------------------------------------------------------
 
     no        id   name            status     mothers   daughters     colors      px        py        pz             
     0        90   (system)           -11     0     0     0     0     0     0      0.000      0.000      0.000   8000.000  
     1      2212   (p+)               -12     0     0     3     0     0     0      0.000      0.000   4000.000   4000.000     
     2      2212   (p+)               -12     0     0     4     0     0     0      0.000      0.000  -4000.000   4000.000     
     3        21   (g)                -21     1     0     5     8  \color{green!80!black} 504  \color{blue} 503   \color{black}   0.000      0.000     94.198     94.198    
     4        21   (g)                -21     2     0     5     8  \color{yellow!80!black} 501  \color{green!80!black} 504 \color{black}     0.000      0.000   -466.748    466.748     
     5         6   (t)                -22     3     4     9    10  \color{yellow!80!black} 501 \color{black}    0     81.617    -59.344   -265.703    333.045    
     6        -5   bbar                23     3     4     0     0     0 \color{red}  502  \color{black}   -0.916    -37.444    -61.245     71.944   
     7         3   s                   23     3     4     0     0   \color{red}502 \color{black}    0    -54.108     10.412     -0.850     55.107      
     8        -4   cbar                23     3     4     0     0     0   \color{blue}503\color{black}    -26.593     86.377    -44.751    100.851     
     9        24   (W+)               -22     5     0    11    12     0     0     86.539    -59.228    -98.855    166.058    
    10         5   b                   23     5     0     0     0  \color{yellow!80!black} 501 \color{black}    0     -4.922     -0.116   -166.849    166.988     
    11       -13   mu+                 23     9     0     0     0     0     0     33.200      0.577      6.352     33.807     
    12        14   nu mu               23     9     0     0     0     0     0     53.339    -59.805   -105.207    132.250      
                                   Charge sum:  0.000           Momentum sum:     -0.000      0.000   -372.550    560.947   
 
\end{Verbatim}         
\endgroup    
\end{center}
\caption{Examples of the flipped portions of an LHE file used to generate the octet-$W$ sample. The flip occurs on lines 6 and 7.}
\label{fig:color:reconstructing:defining:flip}
\end{figure}

Samples are produced with both \PowPythia and \PowHerwig generator+showering model schemes. Figure~\ref{fig:color:motivation:validation} shows the difference, at truth level, between the pull angle between two jets using the nominal color flow in black, and the flipped in blue. The difference is clear: the nominal shows a peak at zero, while the flipped is much more isotropic, as expected.

\begin{figure}
\begin{center}
\includegraphics[width=0.48\textwidth]{cf_int/ThetaJ1J2flip_noflip}
\includegraphics[width=0.48\textwidth]{cf_int/ThetaJ1J2qflip_noflip}
\caption{The pull vector angle between $J_1$ and $J_2$, for the nominal $t\bar{t}$ sample in black, and the flipped in blue. The left plot shows this calculated with all truth particles associated to the jet; the right shows the calculation with only the tracks. All figures are at truth level.}
\label{fig:color:motivation:validation}
\end{center}
\end{figure}

Figure~\ref{fig:color:motivation:validation} shows one additional interesting element of the analysis: while the left-hand plot shows the pull angle calculated with all particles-- i.e., what a measurement using the calorimeter corresponds to-- the right hand plot shows the pull angle using only the \textit{charged particles}-- i.e., what the inner detector measures. Both show significant discrimination power, even though the charged-only measurement is throwing away 1/3 of the particles (the neutrals). The advantage of performing two measurements is that the experimental systematics are completely different for each: uncertainties on the tracker have a very different character from that of the uncertainties on calorimeter objects. Moreover, while the charged particle measurement throws away a significant amount of information, each particle is measured with a significantly better resolution: the \pt measurement of a track does not suffer the response fluctuations which dominate the resolution of a calorimeter. Thus, we proceed with both analyses in parallel-- many aspects of them will be shared, but some will be different, and the ultimate power of each result can be compared at the end.


Thus, the goal of our analysis to obtain a pure sample of hadronically decaying $W$-bosons, and to measure the pull angle between the jets initiated by the decay of the $W$. To better allow the measurement to be utilized by theorists for generator tuning, and to compare to other models of color flow more easily, the analysis is corrected for detector resolution and efficiency effects and \textit{unfolded} to particle level. At this stage, a comparison can be made between the data, the singlet MC, and the octet MC, and we can determine whether the data is able to tell the difference between the two possibilities. All stages of the analysis are performed with both topological calorimeter clusters, which measure all interacting particles in a jet, and tracks reconstructed from the inner detector, which measure only the charged particles but with much improved resolution.

	\subsection{Finding Top Quarks}

	The following section discusses the object selections and cuts used to define the $t\bar{t}$ sample used in the analysis.

	\subsubsection{Trigger}

	As the analysis is semi-leptonic in order to guarantee a high purity of $t\bar{t}$ events, it is sensible to also use the lepton triggers. A logical OR between {\tt EF\_mu24i\_tight}, {\tt EF\_mu36\_tight}, {\tt EF\_e24vhi\_medium} and {\tt EF\_e60\_medium} is used for the whole data taking period. The first and second triggers are the muon triggers; the third and fourth are the electron triggers. The numbers in the trigger name refer to the \pt threshold of the online trigger. The first and third triggers require isolation at the trigger level, thereby allowing a lower \pt threshold; the second and fourth have no isolation requirement, but a much higher \pt treshhold. The \pt $>$ 25~GeV cut on the offline lepton-- described below-- guarantees that the combination of isolated and non-isolated triggers are fully efficient.

	\subsubsection{Selection Objects}

	This analysis makes use of many different object types: jets, $b$-tags, electrons, muons, and \met. The exact quality and selection requirements for each are discussed below.

	\textbf{Electrons} are tracks matched to isolated EM calorimeter clusters\footnote{EM clusters for electrons are composed of 3x3 cells.\editnote{Check this further}}, refit via a Gaussian Sum Filter technique to take into account the larger material interactions and radiations of electrons compared to the initial pion hypothesis~\editnote{Cite}. For this analysis, they are required to pass the \texttt{Tight++} requirement with ``author'' equal to 1 or 3-- this is a set of cuts on the shape of the electron cluster which suppresses backgrounds from jets and photons, and on track quality. The \pt of the electron is set to $E_\mathrm{cluster} / \cosh \eta_\mathrm{cluster}$, and $|\eta| < 2.47$ is required. In addition, the so-called ``crack'' region of $1.37 < |\eta| < 1.52$ is vetoed. To require consistency with the primary vertex, a requirement on the track of $|z_0| < 2$~mm with respect to the primary vertex is imposed. Furthermore, basic quality criteria are applied to reject electrons reconstructed from noisy or dead calorimeter clusters. The energy in a $\Delta R < 0.2$ cone (measured with calorimeter cells) and the \pt within a $\Delta R < 0.3$ cone (measured with tracks) are required to be small. This isolation requirement-- used to suppress electrons from leptonic $B$ decays and fakes from jets in general-- is tuned to select $90\%$ of all electrons. Finally, electrons are required to be isolated from the signal jets (defined below): the jet is removed in favor of the electron if $\Delta R < 0.2$ between any pair, and electrons are removed if $0.2 < \Delta R < 0.4$: this selection is optimized to efficiently keep electrons which are ``faking'' jets (very easy to do, as calorimeter clusters from the electron enter into jet clustering), while removing events where a real jet has emitted an electron (in leptonic $B$-decays, for example). Since this analysis is single-lepton, the electron is also required to match to the trigger electron.

	\textbf{Muons} are generally inner detector tracks matched to muon-spectrometer tracks (though various combinations are possible-- inner detector only, muon-spectrometer only, inner detector with a calorimeter tag, etc.). The muons in this analysis are required to be `tight' combined muons, indicating that tracks are indepenently constructed in both systems and well matched via the Muid algorithm. Cuts of $\pt > 25$~GeV and $|\eta|<2.5$ are applied. Several requirements on the track quality are applied: a b-layer hit is required if expected, and the number of silicon hits is required to be greater than 4, with the number of holes (crossings with no hit, but one expected) to be < 3. The $|z_0|$ is again required to be $< 2$ mm from the primary vertex. Additional requirements on the TRT hits are also applied. The isolation is defined using a variable cone scaling, summing the $\pt$ of all tracks within a cone of size $\Delta R < 10~\mathrm{GeV} / \pt^{\mu}$: the scaling allows the better reconstructed high-\pt muons to not be removed by crossings with jets as the boost of the top quark increases. The cut applied is $I_\mathrm{mini} / \pt^{\mu} < 0.05 $.  Muons are also required to be isolated from jets with a cone of $\Delta R < 0.4$. Similarly to the electrons, a good muon candidate must also match to a trigger muon.

	\textbf{Jets} are reconstructed as per the discussion in Chapter~\ref{chapter:jet-reconstruction}. Cuts of $\pt > 25$~GeV and $|\eta| < 2.1$ are imposed; the $\eta$ requirement is tighter than for other objects to insure that the jet is fully enclosed in the tracker so that the jets can be effectively $b$-tagged. For jets with $\pt < 50$~GeV a JVF cut of $\mathrm{JVF} > 0.5$ is required to reduce the impact of pileup jets. The origin correction of the jet is a particularly important element of the analysis, as the pull vector is very sensitive to the choice of axes. As described below, the topo-clusters are origin-corrected, removing smearing due to the changing $z$-location of the primary vertex, and the sum of their 4-vectors are used as the jet axis. The calibrated $\eta$ is not used, as it is offset from the center of the clusters, and this can produce lare biases in the pull angle.

	\textbf{B-tags} are defined using the MV1 algorithm at a $70\%$ efficiency operating point.

	\textbf{Missing energy} is calculated using all the calibrated signal objects in the analysis, and the un-associated topo-clusters in the calorimeter which form the ``soft term'' which measures the underlying event. The entire method is referred to as \texttt{METRefFinal}.


	\subsubsection{Selection Cuts}

The following cuts are used to define the data sample:
%
\begin{enumerate}
\item Require that there were no large scale detector or calorimeter issues during the event (GRL and detector quality cuts)
\item Require one primary vertex associated with five or more tracks with $\pt > 0.4$~GeV
\item Require either the electron or muon trigger to have fired
\item Require exactly 1 good muon or electron (depending on which trigger fired)
\item Require that no jets with $\pt > 20$ GeV fail quality criteria
\item Require that there exist 4 or more jets with $\pt > 20$~GeV and $|\eta| < 2.5$
\item Require $\met > 20$~GeV
\item Require $\met + m_T > 60$~GeV\footnote{The $m_T$ variable is the transverse mass, associated with the visible mass of the leptonically decaying $W$ boson. It is defined as $m_T^2 = 2 \pt^{\mathrm{lep}} \met (1 - \cos(\Delta \phi))$.}
\item Require 2 $b$-tagged jets
\item Require 2 non-$b$-tagged jets
\end{enumerate}
%
This is mostly a very standard selection for semileptonic $t\bar{t}$, and has been used by ATLAS in many analyses very consistently and effectively \editnote{Cite this.}. One change with respect to the standard selection is a change to point 9: the nominal selection chooses only 1 $b$-tag, but we select 2 in order to more accurately classify and label the event. For this same reason, we require 2 non-$b$-tagged jets: this allows for less ambiguity, as we have much stronger confidence that the $b$-jets from the top quark decay are appropriately identified. Figure~\ref{fig:color:selection:labeling_diagram} displays a diagram summarizing the object selections and the labeling scheme adapted: by requiring 2 $b$-tagged jets, we can easily label $B_1$ and $B_2$ (ordered in \pt).

%%%%%%%%%%%%%%%%

\begin{figure}
\centering
\includegraphics[width=0.7\textwidth]{cf_int/diagram2.pdf}
\label{fig:color:selection:labeling_diagram}
\caption{A diagram explaining the labeling of objects in the $t\bar{t}$ selection used for the analysis.}
\end{figure}

%%%%%%%%%%%%%%%%  

The remaining question is how to assign the label of $J_1$ and $J_2$ in the case when there are more than 2 non-$b$-tagged jets. There are two main possibilities: one could simply take the leading two jets in \pt, or take the two which form the mass closest to the $W$ mass. In this analysis, we adopt the former, as it has several advantages. First, it is an easier scheme to compare to theory results, as requiring the leading two jets in truth is a simple requirement-- whereas $W$ mass requirements impose additional modeling uncertainties, for example. Second, the color flipped sample changes the mass distribution of the $W$ slightly, which would change the efficiency of selection of the singlet and octet. In order to be sure that it is color flow we are observing, and not mass changes, it is better to use a selection which does not introduce this bias\footnote{Note that we studied a reweighting of the mass distribution of the color-flipped sample to the ``nominal'' mass distribution to study the effect on the pull distribution, and there was no effect. This means that the mass changes and the color flow changes are separate effects, but it is still more straightforward to choose the simpler \pt based labeling.}.

Note that the following analysis uses the pull angle of the $J_1$ with respect to $J_2$: while it is possible to use the pull angle of $J_2$ with respect to $J_1$, the resolution actually suffers (as described in Section~\ref{chapter:color:reconstruction:resolution}) and the added statistics would not strongly benefit the analysis.

Finally, a dedicated truth selection mimicing the reco-level selection is implemented for truth-level studies. This selection provides a fiducial region for targetting the unfolding. Final state electrons and muons are used as the leptons; photons with $\Delta R < 0.1$ are assumed to originate from radiation from the lepton and are added back to the 4-vector. Final state neutrinos that do not originate from a hadron are used to determine the missing energy. Jets are clustered from final state particles that are not leptons or neutrinos. $b$-jets are labelled via a ghost-association scheme: truth $B$-hadrons with $\pt > 5$~GeV are allowed to participate in the clustering of the truth jets (though with a scaled, ghost-level \pt) and the jet to which they are clustered is labelled as originating from a $B$-hadron. All the same cuts from the reco-selection are then applied to the truth-objects.

	\subsubsection{MC Backgrounds}

While the selection above is optimized to select $t\bar{t}$ events with very high purity, there are inevitably many different sources of background which must be assessed. The backgrounds are assessed in three ways: directly with MC simulation, using data-driven techniques, or a combination of the two. First, we discuss the MC-driven background estimates.

\textbf{Single top} is assessed in the $s$, $t$, and $Wt$ channel using samples generated with \PowPythia. The $Wt$ channel assess its interference with the nominal $t\bar{t}$ sample using the ``Diagram Removal'' scheme, while the contrasting ``Diagram Subtraction'' scheme is used to assess the theoretical systematics on the sample. The $Wt$ channel contributes the most, and is a non-negligible background.

\textbf{Diboson} production is simulated using \Sherpa version 1.4.1; this generator is found to model the production of dibosons in association with heavy flavor quarks-- i.e., that final state with the largest contribution to our selection-- better than \Herwigpp and other generators. This background is negligible.

\textbf{$\mathbf{Z}$+jets} are assessed with \Alpgen interfaced with \Pythia, generated with separate samples for each additional emission up to 5 partons. All the samples require the $Z$ to decay leptonically in order to provide the leptons required for the analysis selection (hadronically decaying $Z$+jet events do not contribute to the selection). Dedicated filtered heavy flavor samples are produced, and the overlap with the inclusive samples is assessed with the ``Heavy Flavor Overlap Removal'' (HFOR) scheme. The $Z$+jets background is very small.

\textbf{$\mathbf{W}$+jets} are assessed similarly to the $Z$+jets: \Alpgen is interfaced with \Pythia, and separate samples are generated for each real emission, up to 5 partons. All the $W$'s are required to decay leptonically, mimicing the leptonic $W$ in the $t\bar{t}$ decay. Separate samples are generated also for heavy flavor, with both $c$ and $b$ quarks; once again, the overlap is assessed using HFOR. The $W$+jets background is the largest in the analysis, and so a data-driven normalization (described below) is derived to ensure that it is accurately modeled. 


	\subsubsection{Data-Driven Backgrounds}

The normalization on \textbf{$\mathbf{W}$+jets} is assessed with a \textit{lepton-charge-asymmetry} technique. More $W^+$ than $W^-$ events are produced at the LHC because the input hadrons are both positive. The ratio of these two, $r_{MC}$, is better predicted than the absolute cross-section. To derive a scale factor, we note that the sum of both charge types over the difference of charge types should be equal, up to the scale factor $\alpha$:
%
\begin{equation}
\alpha \frac{N_\mathrm{data}^+ + N_\mathrm{data}^-}{N_\mathrm{data}^+ - N_\mathrm{data}^-} = \frac{N_\mathrm{MC}^+ + N_\mathrm{MC}^-}{N_\mathrm{MC}^+ - N_\mathrm{MC}^-}
\end{equation}
% 
which we can rewrite with the ratio $r_{MC}$ as:
%
\begin{equation}
\alpha \frac{N_\mathrm{data}^+ + N_\mathrm{data}^-}{N_\mathrm{data}^+ - N_\mathrm{data}^-} = \frac{1 + r_{MC}}{1 - r_{MC}}
\end{equation}
%
which allows us to solve for the scale factor:
%
\begin{equation}
\alpha W = \frac{1 + r_{MC}}{1 - r_{MC}} \left( N_\mathrm{data}^+ - N_\mathrm{data}^- \right)
\end{equation}
%
where $W$ is the inclusive $W$+jets sample (i.e. the sum of both charges). This scale-factor is derived in bins of jet multiplicity, and separetely for events with and without a $b$-tag\footnote{The scale-factor from the one-tag sample was determind to be consistent with the two-tag sample, which more closely corresponds to our selection}. The data-sample used is enriched in $W$+jets events to a very high purity, though background contributions from $t\bar{t}$, etc. mostly do not matter because they are largely charge-symmetric and drop out of the scale factor.

The shape of the $W$+jets background therefore is taken from MC, but the normalization is corrected using this data-driven approach, substantially reducing the theoretical uncertainties on the largest background to the analysis. The values derived are $1.3 \pm 0.03$ for the $bb/cc$ component, $0.74 \pm 0.04$ for the single $c$ component, and $0.96 \pm 0.02$ for the light component.

\textbf{Multi-jet backgrounds} are very poorly modelled in the simulation, as fake leptons are difficult to describe correctly. A data-driven approach called the \textit{matrix method} is therefore adopted to assess this background~\cite{MatrixMethod}. The goal of the method is to assess $N_\mathrm{fake}^\mathrm{tight}$: the number of fake ``tight'' leptons produced by multi-jet events.  This number is derived using two samples, differing only in the definition of the leptons: either the ``tight'' nominal selection (described above), or a ``loose'' selection with some of these requirements removed (the differences in the loose selection for muons and electrons, which are assessed separetely in this technique, will be described below). A tight lepton, by definition, passes the loose requirements. The tight sample mostly contains real leptons, while the loose sample is enriched in the fakes we are trying to measure, but both samples are a mixture. Thus, we can write:
%
\begin{align}
N^\mathrm{loose} &= N_\mathrm{real}^\mathrm{loose} + N_\mathrm{fake}^\mathrm{loose}\\
N^\mathrm{tight} &= N_\mathrm{real}^\mathrm{tight} + N_\mathrm{fake}^\mathrm{tight}
\end{align}
%
In addition, we can define the \textit{efficiency} of the tight selection as:
%
\begin{equation}
\epsilon_\mathrm{x} = \frac{N^\mathrm{tight}_\mathrm{x}}{N^\mathrm{loose}_\mathrm{x}}
\end{equation}
%
where $x$ is either real or fake-- we are simply stating that the tight selection has a different efficiency of selecting real and fake leptons (i.e. it should be rather efficient for real leptons, but very low efficiency for fake leptons). The efficiencies $\epsilon_\mathrm{x}$ are measured separately in data (via a method described below), so we can take these as given for now. Plugging all these equations together, it is possible to solve for our desired quantity:
%
\begin{equation}
N_\mathrm{fake}^\mathrm{tight} = \frac{\epsilon_f}{\epsilon_r - \epsilon_f} \left(\epsilon_r N^\mathrm{loose} - N^\mathrm{tight} \right)
\end{equation}

In order to derive kinematic distributions-- and not just an overall number-- this quantity can be converted to a series of weights for each event $i$:
%
\begin{equation}
w^i = \frac{\epsilon_f}{\epsilon_r - \epsilon_f} (\epsilon_r - \delta_i)
\end{equation}
%
where $\delta_i = 1$ if the event passes the tight selection, or $\delta_i = 0$ otherwise. These weights are further normalized such that $\sum_i w_i = N_\mathrm{fake}^\mathrm{tight}$. When run over the entire dataset, these weights thus provide the expected multi-jet contribution to the selection.

Loose electrons are defined using the \texttt{medium++} quality criteria, with an additional requirement of a photon conversion veto (which is normally part  of the \texttt{tight++} requirements). There is also no isolation applied. Together, these cuts substantially enrich the loose sample with fake leptons. Loose muons are similar: only the isolation requirement is dropped.  

Efficiencies for real leptons are measured using a tag-and-probe method in leptonic $Z$ decays: a tight lepton (the tag) is used to study loose leptons (the probe). The number of probes (i.e. loose leptons) which pass a tight requirement gives a measurement for $\epsilon_\mathrm{real}$. 

Efficiencies for fake leptons are measured using a control region which inverts the \met and $m_T$ requirements, lowers the requirements on the number of jets, and loosens the $d_0$ cut on leptons. This enriches a sample of fake leptons with kinematics similar of the signal region, but still contains a great deal of real leptons: these must be subtracted out by using MC simulation.

\subsubsection{Data/SM Yields}

Now that all the backgrounds have been assessed, we can compare the data and SM prediction yields after the selection described above. Table~\ref{tab:color:yields:yields} shows the predicted and observed values; the sample has an excellent $t\bar{t}$ purity of $91\%$. The muon channel comprises $53\%$ of the data, so slightly more than the electron channel. Note that the $t\bar{t}$ in this section is always the nominal color flow \PowPythia sample.


\begin{table}
  \centering
  \vspace{3mm}
  \begin{tabular}
  {
 c
 S[table-format=1,
   table-figures-uncertainty=0,group-digits = false,tight-spacing]
}
    \toprule
    Process                      & Counts                                   \\
    \midrule
    $t\bar{t}$                   & 95400 \hspace{1mm}$\pm$\hspace{1mm} 200  \\
    $Wt$-chan single top         & 2730\hspace{1mm} $\pm$\hspace{1mm} 40    \\
    $s$- and $t$-chan single top & 150\hspace{1mm} $\pm$\hspace{1mm} 1      \\
    $W$+jets                     & 3710\hspace{1mm} $\pm$ \hspace{1mm}70    \\
    $Z$+jets                     & 560 \hspace{1mm}$\pm$ \hspace{1mm}10     \\
    Dibosons                     & 190\hspace{1mm} $\pm$\hspace{1mm} 10     \\
    Multijets                    & 2500\hspace{1mm} $\pm$ \hspace{1mm}40    \\
    \midrule
    Total SM                     & 105000 \hspace{1mm}$\pm$ \hspace{1mm}220 \\
    Data                         & 102987                                   \\
    \bottomrule
  \end{tabular}
  \caption{Estimated sample composition.  $W$+jets and multijets estimations are data-driven. Only uncertainties due to finite statistics are listed.}
  \label{tab:color:yields:yields}
\end{table}

We can also make comparisons between the data and SM expectation for the various kinematic quantities of the events (and in particular, the $W$-candidates) to validate that the modeling is well predicting the data distributions well. Figures~\ref{fig:color:yields:pt} and \ref{fig:color:yields:pts_sub} show the leading and subleading $W$-jet candidates' \pt distributions for the muon (left) and electron (channels) in right. The purity of the $t\bar{t}$ sample is immediately clear, but more concerning is the slope seen in the data/SM ratio. This is a well known effect related to the mismodelling of the top quark \pt in many MC simulations. Tests were performed to reweight the \pt distributions in simulation to agree with the data and to check if this had any impact on the pull angle observables: the result was a negligible change, and so this effect is not considered important\footnote{Indeed while the pull vector is normalized by the jet \pt, the angle is not directly affected.} Note also that the uncertainties in this plot (and all subsequent plots) include all detector effects described in Section~\ref{chapter:color:uncertainties:other}, but no theoretical uncertainties from Section~\ref{chapter:color:uncertainties:theory}. In all cases, the MC simulation is normalized to the luminosity.


\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.45\textwidth]{cf_int/DataMC/J1pT}\includegraphics[width=0.45\textwidth]{cf_int/DataMC/J1pTe}
 \caption{The leading $W$ daughter jet $p_T$ for the muon channel (left) and the electron channel (right).}
 \label{fig:color:yields:pts}
  \end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.45\textwidth]{cf_int/DataMC/J2pT}\includegraphics[width=0.45\textwidth]{cf_int/DataMC/J2pTe}
 \caption{The sub-leading $W$ daughter jet $p_T$ for the muon channel (left) and the electron channel (right).}
 \label{fig:color:yields:pts_sub}
  \end{center}
\end{figure}



Figures~\ref{fig:color:yields:etas} and \ref{fig:color:yields:etas_sub} show the same type of distributions for the leading and subleading jet $\eta$. The angular distribution of the jets is very well modelled in MC.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.45\textwidth]{cf_int/DataMC/J1eta}\includegraphics[width=0.45\textwidth]{cf_int/DataMC/J1etae}
 \caption{The leading $W$ daughter jet $\eta$ for the muon channel (left) and the electron channel (right).}
 \label{fig:color:yields:etas}
  \end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.45\textwidth]{cf_int/DataMC/J2eta}\includegraphics[width=0.45\textwidth]{cf_int/DataMC/J2etae}
 \caption{The sub-leading $W$ daughter jet $\eta$ for the muon channel (left) and the electron channel (right).}
 \label{fig:color:yields:etas_sub}
  \end{center}
\end{figure}



Figures~\ref{fig:color:yields:deltaR}, \ref{fig:color:yields:mass}, and \ref{fig:color:yields:wpt} show various aspects of the combined $W$-system. Figure~\ref{fig:color:yields:deltaR} shows the agreement in data/simulation in the $\Delta R$ between the two jets: as this is something which could potentially bias the pull angle measurement, it is reassuring to see it is well modelled. Figure~\ref{fig:color:yields:mass} shows the dijet mass: once again, very good agreement is seen, and moreover, a very convincing $W$-mass peak, highlighting the $W$-purity of the sample. Finally, Figure~\ref{fig:color:yields:wpt} shows the $\pt$ of the $W$ system: the ratio here shows the same slope seen in the individual jet distributions.


\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.45\textwidth]{cf_int/DataMC/DeltaR}\includegraphics[width=0.45\textwidth]{cf_int/DataMC/DeltaRe}
 \caption{The $\Delta R$ between $J_1$ and $J_2$ for the muon channel (left) and the electron channel (right).}
 \label{fig:color:yields:deltaR}
  \end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.45\textwidth]{cf_int/DataMC/WM}\includegraphics[width=0.45\textwidth]{cf_int/DataMC/WMe}
 \caption{The dijet invariant mass of the combination of the leading and subleading $W$ daughter candidate 4-vectors for the muon channel (left) and the electron channel (right).}
 \label{fig:color:yields:mass}
  \end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.45\textwidth]{cf_int/DataMC/WpT}\includegraphics[width=0.45\textwidth]{cf_int/DataMC/WpTe}
 \caption{The $p_T$ (right) of the combination of the leading and subleading $W$ daughter candidate 4-vectors for the muon channel (left) and the electron channel (right). }
 \label{fig:color:yields:wpt}
  \end{center}
\end{figure}



\FloatBarrier



	\subsection{Substructure Objects}

Having obtained a high-purity sample of hadronically decaying $W$'s in both data and simulation, we can now begin to study the actual pull angle distribution. The first step is to define the input objects for the pull vector calculation.

	\subsubsection{Topological Calorimeter Clusters}

Topological calorimeter clusters are familiar objects by now: these are the inputs to jet clustering, and are used to calculate substructure moments in many different analyses. Much has already been said on the topic in Section~\ref{jet-reconstruction:jet-inputs:topoclustering}, and everything discussed there is used for the color flow measurement. In particular, the locally calibrated clusters are used: as is common for substructure, having all calorimeter elements as close as possible to the true particle scale helps ensure that all particles contribute to the reconstructed substucture moment. 

Additionally, a new correction for the primary vertex origin is applied in this analysis. As discussed in Section~\ref{jet-reconstruction:origin}, the $z$-coordinate of the primary vertex is not necessarily at the origin of the detecotr, and a correction to jets based on the measured location of the vertex can substantially improve the $\eta$ resolution of the jet. As we use standard \akt $R=0.4$ jets in this analysis, this means that the jet axis is origin corrected, but the clusters by default are not.  This leads to a large bias in the $r_i$ terms in the construction of the pull vector: the jet axis is not at the center of the clusters anymore.

One potential solution is to remove the origin correction from the jet axis. However, this is also not ideal: the pull vector (and consequentially, the pull angle) are very sensitive to the $\eta$ resolution, as the $r_i$ term comes in twice in the pull vector definition. One particularly interesting consequence of this is that the pull vector magnitude, especially, is sensitive to the different $\eta$ resolutions in data and MC induced by differing $z$-vertex distributions. Because MC is run before data-taking is finished, it often uses an approximate $z$-vertex distribution predicted to match the data conditions, but this often turns out quite different in practice. Most observables do not depend on this, but the pull vector magnitude does: the un-corrected distribution in XXX shows the large disagreement when there is no correction.

There is a better solution, then: one can correct the \textit{clusters themselves} for the changing location of the primary vertex. The correction is given by: 
%
\begin{align}
z &= R\sinh\eta\nonumber\\
z &\mapsto z' = z - z_\text{corr}\nonumber\\
\eta &\mapsto \eta' = \text{asinh} (z'/R) = \text{asinh}(z/R - z_\text{corr}/R) = \text{asinh}(\sinh(\eta) - z_\text{corr}/R)
\end{align}
%
where $R$ is the radial depth of the cluster. The $p_T$ of the corrected cluster is defined similarly:
%
\begin{align}
p_T=E/\cosh(\eta)\mapsto E/\cosh(\eta')=p_T\cosh(\eta)/\cosh(\eta')
\end{align}
%
As this correction is data-driven (it is not calibrated in MC), it corrects the resolution of both data and MC to the same level. Figure YYY below shows the effect of the correction on the pull vector magnitude: removing the different levels of smearing due to the primary vertex's $z$ location has substantially improved the agreement.

Now that the cluster origins are corrected, we define the jet axis in such a way as to minimize any residual bias: we use the location of the 4-vector sum of the origin-corrected clusters. This is effectively removing the $\eta$ calibration from the jet, and restoring the the axis to the ``center'' of the clusters for the purposes of the substructure calculation.


\subsubsection{Tracks}

Tracks are automatically origin-corrected: there is no assumption of the location of the vertex at the origin of the detector, as the appropriate primary vertex is determined via the measured $z_0$ of the track. However, the axis bias may still exist: since the jet axis is formed from clusters, and not tracks, there is no guarantee that it lies in the center of the tracks. To correct for this, all track pull measurements are constructed with respect to axes formed by summing the 4-momenta of the associated tracks.

Track quality requirements are rather standard. They are required to have $\pt \geq 500$~MeV, $|\eta| < 2.5$, and $\chi^2/\mathrm{ndf} < 3$. Furthermore, 1 hit in the pixel detector at least 6 hits in the SCT are required, and the tracking parameters $z_0^\mathrm{PV} < 2$~mm and $|d_0^\mathrm{PV}| < 2.5$~mm are required. The tracks are ghost associated to the jets, as described in Section~\ref{jet-reconstruction:pileup:ghost-association}.

\subsection{Data/SM Comparisons}
\label{chapter:color:comparisons}

Now that we have defined the input objects to the pull vector, we can begin to show the data/SM agreement of the observable. In the following figures, various corrections described previously are turned on and off to display the importance of each decision. All uncertainties shown include the detector uncertainties described in Section~\ref{chapter:color:uncertainties:other}, and the uncertainties on the clusters/tracks used as inputs to the pull as described in Section~\ref{chapter:color:uncertainties:inputs}.

%% CONTINUE HERE %%
Figure~\ref{fig:color:motivation:pull} shows the pull angle and charged pull angle using the origin corrected jet axis, but uncorrected clusters. Two problems are evident: the bias due to an inconsistent jet center creates a peak at $\pi/2$ in the distribution, and the mismodeling of the jet angular resolution (due to the different beam spots in data and MC) create data/MC difference. Similarly, Figure~\ref{fig:color:substructure:pullq} shows the charged pull angle in a similar configuration. As the tracks are also origin corrected by construction, there is no additional bias due to jet angular resolution, but the bias due to inconsitent axis choice leads to the small peak at $\pi$ in this case.

Both of these issues are corrected by using origin corrected clusters, and always using an axis composed of the 4-vector sum of the inputs to the pull calculation. The corrected versions are shown in Figure~\ref{fig:color:substructure:pull_fixed} and \ref{fig:color:substructure:pullq_fixed}: both show an improvement in the shape (in that there is a peak at 0, and a monotonically falling distribution afterwards) and the data/MC agreement.


\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.425\textwidth]{cf_int/DataMC/ThetaJ1J2}\includegraphics[width=0.425\textwidth]{cf_int/DataMC/ThetaJ1J2e}
 \caption{The jet pull angle for $J_1$ with respect to $J_2$ with the jet origin correction (but no cluster correction) for the muon channel (left) and the electron channel (right). One can clearly see the mis-modelling of the jet angular resolution and inconsistent axis choice. Figure~\ref{fig:color:substructure:pull_fixed} shows the corrected version of this plot.}
 \label{fig:color:substructure:pull}
  \end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.425\textwidth]{cf_int/DataMC/ThetaJ1J2q}\includegraphics[width=0.425\textwidth]{cf_int/DataMC/ThetaJ1J2qe}
 \caption{The jet track pull angle for $J_1$ with respect to $J_2$ with the jet origin correction (but no cluster correction) for the muon channel (left) and the electron channel (right). One can clearly see the bias induced by an incorrect axis choice, especially in the last bin. Figure~\ref{fig:color:substructure:pullq_fixed} shows the corrected version of this plot. }
 \label{fig:color:substructure:pullq}
  \end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.425\textwidth]{cf_int/DataMC/ThetaJ1J2_caxis}\includegraphics[width=0.425\textwidth]{cf_int/DataMC/ThetaJ1J2_caxise}
 \caption{The jet pull angle for $J_1$ with respect to $J_2$ with cluster origin corrections and the jet axis constructed from the four-vector sum of clusters for the muon channel (left) and the electron channel (right). Figure~\ref{fig:color:motivation:pull} shows the uncorrected version of this plot. }
 \label{fig:color:substructure:pull_fixed}
  \end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.425\textwidth]{cf_int/DataMC/ThetaJ1J2q_taxis}\includegraphics[width=0.425\textwidth]{cf_int/DataMC/ThetaJ1J2q_taxise}
 \caption{The jet track pull angle for $J_1$ with respect to $J_2$ were the jet axis is the four-vector sum of tracks for the muon channel (left) and the electron channel (right).  Figure~\ref{fig:color:motivation:pullq} shows the uncorrected version of this plot.}
 \label{fig:color:substructure:pullq_fixed}
  \end{center}
\end{figure}

A similar set of comparisons is now presented for the pull vector magnitude and the charged pull vector magnitude. Figure~\ref{fig:color:substructure:pullmag} uses the origin-corrected jet axis, but uncorrected clusters: the bias in shape due to the incorrect axis, and the disagrement in data/MC induced by the beamspot modeling, is even more evident. To exaggerate the issue even further, Figure~\ref{fig:color:substructure:pullmag_2} shows the same for $J_2$'s pull vector magnitude: though this observable is not used in the analysis, the problematic modeling before the corrections motivates strongly the further steps taken. Figure~\ref{fig:color:substructure:pullmag_fixed} shows the result after the cluser origin correction and jet axis reconstruction: the agreement is again substantially improved.



\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.425\textwidth]{cf_int/DataMC/v1}\includegraphics[width=0.425\textwidth]{cf_int/DataMC/v1e}
 \caption{The jet pull vector magnitude for $J_1$ with the jet origin correction (but no cluster correction) for the muon channel (left) and the electron channel (right). One can clearly see the impact of the mis-modelling of the jet angular resolution and biased axis choice. Figure~\ref{fig:color:substructure:pullmag_fixed} shows the same quantities after corrections for these effects.}
 \label{fig:color:substructure:pullmag}
  \end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.425\textwidth]{cf_int/DataMC/v2}\includegraphics[width=0.425\textwidth]{cf_int/DataMC/v2e}
 \caption{The jet pull vector magnitude for $J_2$ with the jet origin correction (but no cluster correction) for the muon channel (left) and the electron channel (right). One can clearly see the impact of the mis-modelling of the jet angular resolution.}
 \label{fig:color:substructure:pullmag_2}
  \end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.425\textwidth]{cf_int/DataMC/v1_caxis}\includegraphics[width=0.425\textwidth]{cf_int/DataMC/v1_caxise}
 \caption{The jet pull vector magnitude for $J_1$ with cluster origin corrections and the jet axis constructed from the four-vector sum of clusters for the muon channel (left) and the electron channel (right). Figure~\ref{fig:color:substructure:pullmag} shows these same quantities before the corrections.}
 \label{fig:color:substructure:pullmag_fixed}
  \end{center}
\end{figure}


Figure~\ref{fig:color:substructure:pullmagq} shows the un-corrected charged pull vector magnitude: once again, the incorrect axis choice leads to a bias in the shape. Figure~\ref{fig:color:substructure:pullmagq_2} shows the same for $J_2$; again the effect is exaggerated. Finally, Figure~\ref{fig:color:substructure:pullmagq_fixed} shows the charged pull vector magnitude, using the reconstruced track-only jet axis: the shape of the distribution is significantly simplified.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.425\textwidth]{cf_int/DataMC/v1q}\includegraphics[width=0.425\textwidth]{cf_int/DataMC/v1qe}
 \caption{The jet track pull vector magnitude for $J_1$ with the jet origin correction (but no cluster correction) for the muon channel (left) and the electron channel (right). One can clearly see the bias due to the inconsistent jet axis choice. Figure~\ref{fig:color:substructure:pullmagq_fixed} shows the corrected version of this plot.}
 \label{fig:color:substructure:pullmagq}
  \end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.425\textwidth]{cf_int/DataMC/v2q}\includegraphics[width=0.425\textwidth]{cf_int/DataMC/v2qe}
 \caption{The jet track pull vector magnitude for $J_2$ with the jet origin correction (but no cluster correction) for the muon channel (left) and the electron channel (right). One can clearly see the bias due to the inconsistent jet axis choice}
 \label{fig:color:substructure:pullmagq_2}
  \end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.425\textwidth]{cf_int/DataMC/v1q_taxis}\includegraphics[width=0.425\textwidth]{cf_int/DataMC/v1q_taxise}
 \caption{The jet track pull vector magnitude for $J_1$ were the jet axis is the four-vector sum of tracks for the muon channel (left) and the electron channel (right). Figure~\ref{fig:color:substructure:pullmagq} shows the uncorrected version of this plot. }
 \label{fig:color:substructure:pullmagq_fixed}
  \end{center}
\end{figure}



\FloatBarrier

	\subsection{Resolution Effects}
	\label{chapter:color:reconstruction:resolution}

Having established the basic event selection, object construction, variables used, and data/MC agreement, it is useful to also consider the experimental \textit{resolution} of various choices in the analysis. Figure~\ref{fig:color:resolution:objects} shows the pull angle response for $J_1$, defined as the difference between the truth pull angle and the reconstructed pull angle for the same event, using several different objects as inputs to the calculation. All the distributions are centered at zero, indicating that on average the correct pull angle is being reconstructed; however, the width of the distribution changes dramatically the input object used. In particular, the origin uncorrected clusters show the worst resolution: the smearing induced by the beamspot modeling is substantial, and simply origin correcting the clusters improves the resolution significantly. Tracks, finally, have the best resolution by far: while the neutrals are being thrown away and the amount of information is reduced in principle, the fact that the tracks are so much better measured than calorimeter clusters leads to a significantly improved quality of the measurement.



\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.45\textwidth]{paper/otheraux3}
 \caption{The pull angle response (defined as $\theta_\mathrm{truth} - \theta_\mathrm{reco}$), for $J_1$, measured in several ways: clusters before origin correction, clusters after origin correction, and using tracks.}
 \label{fig:color:resolution:objects}
  \end{center}
\end{figure}

Figure~\ref{fig:color:resolution:pt} shows the resolution (the RMS of the response) as a function of the \pt of $J_1$. There is a clear improvement in the resolution as a function of \pt; however, no additional selection is imposed on $J_1$. Instead, this motivates the use of only $J_1$ to measure the color flow, and to ignore the lower \pt jet $J_2$.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.45\textwidth]{pull_conf/fig_08}
 \caption{The resolution (the RMS of the response) for the charged and all particles pull angle, as a function of the \pt of $J_1$.}
 \label{fig:color:resolution:pt}
  \end{center}
\end{figure}


Figure~\ref{fig:color:resolution:mag} shows the resolution as a function of the pull vector magnitude: the resolution steadily improves as the magnitude increases. This is easily explained: with a larger magnitude, the jet is \textit{leaning} more strongly in some particular direction, and it is less likely that fluctuations can disrupt this larger effect. The effect is quite dramatic, and so a cut on the pull vector magnitude is considered in the final optimization of the analysis.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.45\textwidth]{pull_conf/fig_09b}
 \caption{The resolution (the RMS of the response) for the charged and all particles pull angle, as a function of the pull vector magntitude.}
 \label{fig:color:resolution:mag}
  \end{center}
\end{figure}


\section{Uncertainties}

With the details of the measurement defined, the uncertainties are the next topic that should be addressed. There are four main categories of uncertainties:
%
\begin{enumerate}
\item Track and cluster related (related to the measurement)
\item Other detector effects (related to selection)
\item Theoretical uncertainties
\item Unfolding uncertainties
\end{enumerate}
%
The first three will be addressed in the following sections, while the unfolding uncertainties will be addressed in Section~\ref{chapter:color:unfolding:uncertainties} after the unfolding procedure itself is defined.

 Practically, each uncertainty is used to shift the properties of events in simulation in some way (in multiple different ways for some of the uncertainties); the resulting selected events are used to perform the same unfolding procedure as the nominal MC, and the difference in the final result is taken as the systematic. For the reco-level figures of previous sections, the difference between the nominal and systematic selection are summed in quadrature over the variations from the detector objects (non-track and cluster) and theretical uncertainties and the resulting bland is overlaid on the nominal MC distribution.

	\subsection{Track and Cluster Uncertainties}
	\label{chapter:color:uncertainties:inputs}

	The uncertainties on the input objects to the pull calculation are of prime importance to the analysis: they characterize the degree to which the detector gives a consistent measurement of the actual physics of interest to us. These obviously come in two categories: those for tracks, and those for calorimeter clusters. 

	\subsubsection{Track Uncertainties}

	The following uncertainties characterize various aspects of tracking in ATLAS: they all affect only the construction of the charged pull angle.

	The \textbf{Tracking Efficiency} is an assessment which characterizes how well the MC reproduces the efficiency of reconstruction of charged particle tracks in data. This uncertainty is derived by measuring in detail the charged particle multiplicities in minimum bias events \editnote{Cite me, 61 in CF}. The effect on the analysis is estimated by removing tracks from jets with an $\eta$ dependent probability. The effect is largest in the region $2.3 < |\eta| < 2.5$, where the probability is $7\%$; $1.9 < |\eta| < 2.3$ has 4\%; $1.3 < |\eta| < 1.9$ is 3\%, and finally $|\eta| < 1.3$ is 2\%. 


	The \textbf{Track Energy} assessment analyzes the degree to which high \pt tracks in dense environments, such as high \pt jets, may be mismeasured \editnote{Cite this too, 62}. The effect on the analysis is once again assessed by dropping tracks with some chance and then re-calculating the pull angle; in this instance, the probability is parameterized by the associated jet \pt. There are no tracking issues for jets with $\pt < 400$~GeV, so the bulk of the analysis is unaffected. Betweeen 400 and 500 GeV, the probability of removal is $0.08\%$; this rises to $0.8\%$ for jets between 500 and 600 Gev, once again rises to $1.9\%$ for jets between 600 and 800 GeV, and finally is $3.7\%$ for jets between 800 and 1000 GeV. There is no probability derived at higher \pt, but as the analysis has very very few jets with this much energy, this is not an issue.

	The \textbf{Track Energy Resolution} takes into account potential mismeaurements of track \pt, and is again assessed from minimum-bias data~\editnote{Cite 61}. The energy of each track is simultaneously randomly smeared by $10\%$. 

	\subsubsection{Cluster Uncertainties}

	Cluster uncertainties are slightly more complicated, as there are fewer direct physics measurements which can be used to constrain them as was done for the tracker. For most measurements of cluster properties, the corresponding measurement of the tracker is known to be much higher resolution: the tracker measurements can therefore often be used as a standard candle to assess the cluster uncertainties.

	In principle there are two limitations to this approach: first, there is no assessment for $|\eta| > 2.5$, and second, there is no assessment for neutral particles. In terms of the $|\eta|$ acceptance, the jet selection cuts mean that this is not a concern for us. The neutral clusters are more troubling: the uncertainties from charged particles are used on them, which is not strictly correct. However, the overall size of the systematic is very small, and is taken to be very conservative in all cases: if it was a dmoninant component of the analysis, it would be more critical to carefully consider the effect of neutral clusters.

	The \textbf{Cluster Angular Resolution} is measured in $Z\rightarrow \mu\mu$ events, following the example of a 2011 analysis~\editnote{Cite this}. In this technique, isolated tracks and isolated clusters are matched to each other in $\Delta R$ space, using the track position extrapolated to the second layer of the calorimeter. Events with $\pt^{Z} > 30$~GeV are selected: tracks are matched to the closest cluster, and are required to have only one cluster with $\Delta R < 0.5$. Only high quality tracks not belonging to the reconstructed muons are used, and only clusters with $E > 0$ are considered. Example distributions are shown in Figure~\ref{fig:color:uncertainties:clusters:deltar} for the barrel region of the detector. Two peaks are visible in most plots: the second one is always at $\Delta R = 0.15$, and is induced by the requirement of having no additional clusters within this range. There are clearly two peaks in the distribution: the first is interpreted as being caused by the proper charged track being matched to the cluster, while the second is seen as contamination from neutral particles not measured by the tracker. One change from the 2011 study is that a cut on $\Delta R< 0.075$ is performed in order to isolate the first peak: ultimately, this leads to a substantial reduction of the uncertainty compared to 2011.


\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.45\textwidth]{cf_int/Systematics/delta_R_0.pdf}\includegraphics[width=0.45\textwidth]{cf_int/Systematics/delta_R_1.pdf}
\includegraphics[width=0.45\textwidth]{cf_int/Systematics/delta_R_2.pdf}\includegraphics[width=0.45\textwidth]{cf_int/Systematics/delta_R_3.pdf}
\includegraphics[width=0.45\textwidth]{cf_int/Systematics/delta_R_4.pdf}\includegraphics[width=0.45\textwidth]{cf_int/Systematics/delta_R_5.pdf}
\end{center}
\caption{The $\Delta R$ between isolated tracks and clusters in $Z\rightarrow\mu\mu$ events in the barrel of the detector.}
\label{fig:color:uncertainties:clusters:deltar}
\end{figure}

	The peak of each of these histograms (and many others, for various $\eta$ regions in the detector), are compared between data and MC. The $\Delta \eta$ and $\Delta \phi$ are studied separately, as the detector changes in each direction are different. Moreover, various selections are applied to the central position of the cluster to separately study clusters in the different calorimeter subdetectors. These are then characterized as a function of the track momentum $p$ in Figures~\ref{fig:color:uncertainties:clusters:deta} and \ref{fig:color:uncertainties:clusters:dphi}. In all cases, the disagreement is significantly smaller than 1 mrad. In order to be conservative, the analysis ultimately implements a 5 mrad random smearing on the cluster location, as was derived in the 2011 analysis. The effect is still rather small on the ultimate result.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.45\textwidth]{cf_int/Systematics/deta.pdf}
\includegraphics[width=0.45\textwidth]{cf_int/Systematics/deta_LAr.pdf}\includegraphics[width=0.45\textwidth]{cf_int/Systematics/deta_Tile.pdf}
\end{center}
\caption{The differences between data and MC for the RMS of the $\Delta \eta$ between isolated single particle tracks and clusters for various regions of the calorimeter in the barrel.}
\label{fig:color:uncertainties:clusters:deta}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.45\textwidth]{cf_int/Systematics/dphi.pdf}
\includegraphics[width=0.45\textwidth]{cf_int/Systematics/dphi_LAr.pdf}\includegraphics[width=0.45\textwidth]{cf_int/Systematics/dphi_Tile.pdf}
\end{center}
\caption{The differences between data and MC for the RMS of the $\Delta \phi$ between isolated single particle tracks and clusters for various regions of the calorimeter in the barrel.}
\label{fig:color:uncertainties:clusters:dphi}
\end{figure}

	The \textbf{Cluster Energy Uncertainty} is assessed similarly, and uses inputs from the 2012 $E/p$ analysis~\editnote{Cite me}. In that analysis, isolated tracks are matched to isolated tracks (similarly to the previous section) in minimum bias events: the ratio of the calorimeter energy measurement $E$ is then compared to the tracker momentum measurement $p$, as a function of $p$. The ratio of the $E/p$ measurements in data and MC is taken, and a band is drawn on top to bound the change from unity. The band has an analytic form of:
	%
	\begin{equation}
	f_\pm(p|\alpha,\beta)= 1\pm \alpha \times\left(1+\frac{\beta\text{ MeV}}{p}\right),
	\end{equation}
	%
	so the band is parameterized by two terms, $\alpha$ and $\beta$, and $p$ here is taken as the cluster momentum. This band is taken as the uncertainty on the energy measurement of the calorimeter. The $\alpha$ and $\beta$ terms are $\eta$ dependent. Figure~\ref{fig:color:uncertainties:clusters:ep} shows two bins of the $E/p$ meaurement, and the corresponding derived uncertainty band in blue.


\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.45\textwidth]{cf_int/Systematics/e1119_s1743_s1741_r4931_1.pdf}\includegraphics[width=0.45\textwidth]{cf_int/Systematics/e1119_s1743_s1741_r4931_2.pdf}
\end{center}
\caption{The average LCW E/p for $0<|\eta|<0.6$ (left) and $0.6<|\eta|<1.1$. The blue band in the ratio shows the estimated uncertainty used for the cluster energy scale uncertainty.}
\label{fig:color:uncertainties:clusters:ep}
\end{figure}

	Two different approaches are used to assess the impact of $f$, and the most conservative choice is adopted for each bin of the pull angle.

	First, one can use each `up' and `down' component of $f_\pm$, making a coherent shift for all clusters up and down simultaneously (though with different sizes, due to the changes in $\alpha$ and $\beta$ over the detector). This assessment treats the calorimeter uncertainty is global by not allowing local regions to fluctuate up and down independently.

	Second, one can smear the cluster energies with a width of $f_+ - 1$ for each cluster, generating the random numbers for the smearing in strips of $\eta$. This allows for some measure of coherence-- the binning in $\eta$, but allows various unrelated regions of the detector to fluctuate randomly with respect to each other.

	The ultimate size of the uncertainty, even assessed in this conservative manner, is very small.

	\subsubsection{Dead Material Effects}

	One final uncertainty on clusters is related to dead material in the detector. This uninstrumented material (dead in the sense that energy measurements do not take place) is taken into account by the LC scheme in order to improve the energy measurement as discussed in Figure~\ref{fig:jet-reconstruction:cluster-calibration:ooc-dm}, but the dead material can also prevent new clusters from being formed. Using a measurement from $\sqrt{s} = 900$~GeV data, clusters with energy $E < 2.5$~GeV  are randomly removed with probability $r\leq 25\%\times \exp(-2E/\text{GeV})$. 

	\subsubsection{Jet Angular Resolution Uncertainty}

	Note that in principal, the angular uncertainty on jets can be measured directly in data, and indeed, \editnote{CITE THIS} does exactly this. Since the jet axis choice has been shown to have a large impact on the analysis, this is clearly an important effect, and the corresponding uncertainty should be assessed. However, for the reasons previously discussed, the jet axis for the calculation of the pull quantities is computed from the specific corrected objects used in the construction of the pull. As these objects already have corresponding angular uncertainties-- discussed previously-- these uncertainties can be assessed from their effect on the input objects, as they are directly propagated to the jet axis.  

\FloatBarrier

	\subsection{Other Detector Uncertainties}
	\label{chapter:color:uncertainties:other}

	This section describes the various sources of uncertainty that arise from the measurement of the properties of events used in the selection. In all cases, these assess the degree to which the MC predicts the properties of some object in the event.

	\editnote{These all should be cited.}

	The \textbf{Jet Energy Scale} (JES) uncertainty describes the precision to which the \pt of a jet is understood, as described in Section~\ref{chapter:jet-reconstruction:insitu}. The JES is known to a few percent; its main effect on the analysis is its effect on the acceptance of jets, as the \pt threshold of 25 GeV is sensitive to variations in the \pt scale.

	Note that there is one other place the \pt uncertainty comes into play: the pull vector magnitude is normalized by it. This means that if the analysis cuts on the pull vector magnitude in order to improve the pull angle resolution, it also has the effect of increasing the effect of the JES on the analysis.

	Note finally that the acceptance change affects both the all particles and charged particles measurements, as the selection is common between the two of them.

	The \textbf{Jet Energy Resolution} (JER) is similar to the JES, except it a measurement of the \textit{width} of the energy response instead of the mean value. In some \pt and $\eta$ regions, the energy resolution in MC is overly optimistic, so a smearing is applied to take this into account; a corresponding uncertainty characterizes the accuracy of this assessment (performed very similarly to the in-situ JES analyses of Section~\ref{chapter:jet-reconstruction:insitu}, but always measuring the width instead of the mean). Similarly to the JES, this affects mainly the acceptance, but if a cut on the pull vector magnitude is performed, the resolution's impact is amplified. Finally, as with all acceptance effects, the JER affects both the all particles and charged particles measurements.


	The \textbf{Luminosity Uncertainty} is $\pm2.8\%$. It is derived, following the same methodology as that detailed in \cite{ATLASLumi}, from a preliminary calibration of the luminosity scale derived from beam-separation scans performed in November 2012. The final measurement subtracts backgrounds from the data to perform the unfolding, so the luminosity uncertainty only comes into play on the normalization of the backgrounds that are estimated from MC (i.e. the diboson, single top, and $Z$+jets components). Since the $W$+jets and multijet backgrounds are derived (or at least normalized) to data, the luminosity uncertainty does not affect them.

	\textbf{Lepton uncertainties} come in several types, but affect the analysis only minimally: they are much smaller than the JES uncertainties, and since only one lepton is required, the effect is not increased by the multiplicity requirements. There are separate components for muon and electron trigger scale factors: these parameterize the understanding of the efficiency of the lepton triggers. There are also uncertainties on the lepton efficiency, characterizing the performance of lepton reconstruction, especially taking into account the uncertainty on the cuts used to define the ``tight'' leptons used in the analysis. Both the lepton trigger and lepton general uncertainties are on efficiencies, so they act as scale factors on the event without changing the raw acceptance. Finally, there are uncertainties on the lepton energy scale and resolution: these directly affect the acceptance of the analysis. All these uncertainties are very tiny, and all affect both the all particles and charged particles measurements.

	\textbf{Missing Energy and Soft Term} uncertainties are related to the measurement of the \met in the event used in the selection. All the jet and lepton energy uncertainties are used to recalculate the \met whenever they are applied, and a separate uncertainty exists for the soft term of the missing energy. The effect on the analysis is again minimal, and affects both the all particles and charged particles measurements.

	\textbf{$\mathbf{b}$-tagging} uncertainties are related to the calibration of the efficiencies of the $b$-tagging on light jets and $b$-jets, as described in Section~\ref{chapter:jet-reconstruction:b-tagging:calibration}. The scale factors derived to take into account data-MC differences in the efficiency of tagging various objects come with uncertainties which characterize the precision of this assessment. The effect on the analysis is not very large, and once again, affects both the all particles and charged particles measurement.


	\subsection{Theoretical Uncertainties}
	\label{chapter:color:uncertainties:theory}

	The final class of uncertainties are the theory uncertainties on the MC prediction. These describe our lack of understanding of various inputs to the MC prediction, and are assessed by changing generators and parton showers, or changing the parameters and inputs to the generators.

	Often the MC samples used to study these uncertainties are only available using the ATLAS Fast-Simulation framework (AFII). AFII is notoriously bad at measuring substructure because it parameterizes the showering processes in the calorimeter somewhat poorly, so direct comparisons between AFII and the full-simulation samples is not possible. For this reason, the uncertainties are assessed by comparing the unfoldings with the nominal \PowPythia $t\bar{t}$ simulated with AFII. As some of these samples also affect the truth prediction which we are ultimately comparing to, we often also show the uncertainty on the truth prediction itself. \editnote{Clean this up, not sure if true}

	\textbf{PDF Uncertainties} reflect our limited knowledge of the proton structure: as these govern the actual inputs to collisions simulated in MC, they can have a broad impact on the scale and rate of events. These are evaluated using the standard PDF4LHC recommendations~\cite{Botje:2011sn} by reweighting events with
	%
	\begin{equation}
    w = \frac{ \mathrm{PDF}(x_1, f_1, Q) \mathrm{PDF}(x_2, f_2, Q) }{ \mathrm{PDF}_0(x_1, f_1, Q) \mathrm{PDF}_0(x_2, f_2, Q) } \ ,
  \end{equation}
  	%
  	where PDF refers to a new PDF set, PDF$_0$ is the nominal, $x$ is the longitudinal momentum fraction of the incoming partons, $f$ is the flavor of the partons, and $Q$ is the scale of the event. Three different PDFsets are compared: the nominal CT10nlo, and the variations of MSTW2008 and NNPDF2.3. The reweighted distributions are used to re-unfold the data: the size of this effect is summarized in Figure~\ref{fig:color:uncertainties:theory:pdf}. The boxes correspond to the uncertainties on each PDF set itself; a band constructed from all of them is used as the PDF uncertainty of the measurement. The effects are clearly negligible, but impact both the all particles and charged particles measurement.


  \begin{figure}
    \begin{center}
    \includegraphics[width=0.45\textwidth]{cf_int/Systematics/PDF_results_PullAllCaloAxis}
    \includegraphics[width=0.45\textwidth]{cf_int/Systematics/PDF_results_PullChargedTrackAxis}
    \caption{The ratio of each PDF set (and their uncertainties) to the
    nominal PDF set.}
    \label{fig:color:uncertainties:theory:pdf}
    \end{center}
  \end{figure} 


  \textbf{Shower Model} uncertainties are more complicated: this is an attempt to assess the dependence of the unfolding procedure on our choice of parton shower description. \Pythia, which uses a color-string model, can predict rather different distributions from \Herwig, which uses an angular-cluster model. Figure~\ref{fig:color:uncertainties:theory:shower} shows some comparisons for the nominal color flow model, and various other simulations, at truth level. The clear result from these comparisons is that changing the hard-scatter (\Powheg to \Mcatnlo for example) does not have a large impact on the distribution, while changing the showering does indeed have a large impact. Due to the limited MC samples available, this systematic is assessed using the flipped MC (the exotic model used to compare against), but cross-checked using several other techniques at truth level.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.45\textwidth]{cf_int/showermodel/ThetaJ1J2flip_noflip_her.pdf}\includegraphics[width=0.45\textwidth]{cf_int/showermodel/ThetaJ1J2qflip_noflip_her.pdf}
\caption{Truth level distributions comparing Pythia and Herwig for the all particles pull angle (left) and the charged particles pull angle (right).  Electron and muon channels combined.}
\label{fig:color:uncertainties:theory:shower}
\end{center}
\end{figure}

	\textbf{Color Reconnection} is expected to have some impact on color sensitive analyses, as it does involve the exchange of color lines between quarks during the parton shower. However, since it is an effect of the parton shower, it is expected to be subdominant compared to the color set by the Matrix Element-- and indeed, and indeed, previously studied variations have shown that the reconnection has a small impact on the pull angle~\cite{Altheimer:2013yza}. Simulated `low color reconnection' truth level samples are used to assess the potential impact: these samples use the lowCR Perugia tune to significant suppress the interactions between partons but not so far as to be inconsistent with minimum bias measurements. The effect is shown in Figure~\ref{fig:color:uncertainties:theory:cr}, and is clearly less than $1\%$. Again, this affects both the all particles and charged particles measurement.


\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.45\textwidth]{cf_int/sirfsr/ThetaJ1J2flip_noflip_mpi.pdf}\includegraphics[width=0.45\textwidth]{cf_int/sirfsr/ThetaJ1J2qflip_noflip_mpi.pdf}
\caption{Truth level distributions comparing the nominal and low CR tunes of Pythia for the all particles pull angle (left) and the charged particles pull angle (right).  Electron and muon channels combined.}
\label{fig:color:uncertainties:theory:cr}
\end{center}
\end{figure}

	\textbf{ISR/FSR} uncertainties reflect our lack of understanding on the production of extra jets due to radiation of quarks or gluons off of incoming our outgoing particles. These are typically assessed by using \Acermc to generate distributions with more or less radiation, and then compared to the nominal distribution. This can have an important effect on the analysis, as the production of jets and dilute the purity of the $W$ selection, as well as having standard acceptance effects. Figure~\ref{fig:color:uncertainties:theory:ISRFSR} shows comparisons of these effects, which are important for both the all particles and charged particles measurements.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.45\textwidth]{cf_int/sirfsr/ThetaJ1J2flip_noflip_isr.pdf}\includegraphics[width=0.45\textwidth]{cf_int/sirfsr/ThetaJ1J2qflip_noflip_isr.pdf}
\caption{The ISR/FSR variations at truth level for the all particle pull (left) and the charged particles pull (right).  Electron and muon channels combined.}
\label{fig:color:uncertainties:theory:ISRFSR}
\end{center}
\end{figure}

	The uncertainty on the \textbf{Top Quark Mass} is assessed by comparing samples with different values of the top quark mass. The effect is negligible.

	The choice of \textbf{Color Flow Model} is the largest uncertainty: this shows the dependence of the analysis on the unfolding using the nominal color flow, and how different the result would be if we changed our prior and unfolded instead with the octet color flow. Since all samples exist in full simulation, this is assessed directly via the unfolding. Because it has a large impact on the unfolding (for reasons described later), it will be discussed in more detail in the following sections.

	Note that while this uncertainty is important for the comparison of the two color flow models, in principle the answer is already known-- the $W$ is a singlet-- and so this uncertainty should be ignored when tuning MC generators.

	\textbf{Background Normalizations} need also to be assessed. $Wt$ single top-- the largest single top contribution-- is evaluated by using a sample with ``diagram subtraction'' as opposed to the nominal diagram removal. The $W$+jets data-driven normalization has several uncertainties associated with the charge asymmetry method; similarly, the multi-jet normalizaiton has uncertainties related to the matrix method (and in particular the measurement of the lepton efficiencies in various samples). $Z$+jets, smaller single top contributions, and dibosons are so small that uncertainties are not considered on them. 

\FloatBarrier

\section{Measuring Color}

Finally, all the preliminaries are defined and the final analysis can proceed. We understand the selection of $t\bar{t}$ events, the data/MC agreement in this sample, and the various sources of uncertainty on our measurement. We can now proceed to \textit{unfold} the pull angle distribution, creating a distribution of data corrected for the various detector effects-- thus allowing us to truly see, or measure, color at the LHC.

	\subsection{Unfolding}

	The problem of unfolding can be thought of as a simple equation:
	%
	\begin{equation}
	\mathbf{A} \cdot \mathbf{x} = \mathbf{y},
	\end{equation}
	%
	where $\mathbf{y}$ is a vector describing some quantity at the reconstructed level, $\mathbf{x}$ is a vector describing the same quantity at truth level, and $\mathbf{A}$ is a matrix which smears $x$ into $y$-- i.e., $\mathbf{A}$ is a detector or detector simulation. Typically one measures $\mathbf{y}$ in data, and then wishes to extract $\mathbf{x}$ from the data: this requires obtaining and then inverting $\mathbf{A}$ in some way. The procedure adopted by this analysis is an \textit{Iterative Bayseian Unfolding}, which assesses the matrix probabilistically. \editnote{add more on this}

	The same problem can be defined in terms of probabilities as:
%
\begin{equation}
  d^\prime_i = \sum_j\mathrm{P}(T_i|M_j)\;d_j  = \sum_{j}\theta_{ij}\;d_j,
\end{equation}
%
	where $d^\prime_i$ is the probability of a measured event occuring in some bin $i$ of a truth distribution, $\mathrm{P}$ is an element of $\theta_{ij}$-- the so-called ``unfolding'' matrix-- and $d_j$ is the probablity of actually measuring the event in the reconstructed bin $j$. $\theta_{ij}$, then, encapsulates our knowledge of the probability of observing an event having a true value in bin $i$, even though we measured it in bin $j$-- something very close to our original matrix $\mathbf{A}$.

	The Bayseian portion of the unfolding comes from our use of Bayes' Theorem to rewrite $\mathrm{P}(T_i|M_j)$ as $\mathrm{P}(M_j|T_i)$: i.e., the probability of having some measured value in a bin $j$, for some truth bin value $i$. This can be written as:
%
\begin{equation}
  \theta_{ij} = \mathrm{P}(T_i|M_j) = \frac{\mathrm{P}(M_j|T_i)\cdot \mathrm{P}(T_i)}{\sum_i \mathrm{P}(M_j|T_i)\cdot \mathrm{P}(T_i)} = \frac{a_{ji}\cdot \mathrm{P}(T_i)}{\sum_i a_{ji}\cdot \mathrm{P}(T_i)} \ ,
\end{equation}
%
	and now the comparison to $\mathbf{A}$ from before is complete: the $a_{ji}$ are the elements of our smearing, or response matrix, from before. The $\mathrm{P}(T_i)$ is referred to as a \textit{prior}: this is the probability of finding an event in bin $i$ of the actual true distribution-- which of course we do not know. However, any reasonable guess for this true distribution often suffices, and there is a procedure to remove the dependence on this prior assumption which will be discussed shortly.

	What exactly has this accomplished? We have been manipulated a matrix $\theta_{ij}$, which can be applied to some normalized reconstructed data distribution $d_j$, in order to obtain a truth-level distribution $d^\prime_i$: this is a tool we can apply to data in order to obtain a real measurement, correcting for detector efficiency and resolution effects. When we started, we had no way of constructing this matrix-- but now, we have found how to define it in terms of $\mathbf{A}$, the response matrix. The response matrix can readily be assessed using MC simulation since the truth and reconstructed quantities are both known, so in principle we have everything we need.

	The previously mentioned downside of the unfolding-- the dependence on the prior $T_i$ distribution-- remains to be addressed, however. The issue is mitigated by applying the procedure \textit{iteratively}-- and so the remaining reason for the naming of the technique becomes clear. Each time the result is unfolded, it is used as a prior to the construction of a new $\theta_{ij}$ and then applied again: each time, the bias due to the choice of the initial $T_i$ decreases. There is a price, however: the statistical fluctuations in the unfolding are amplified as they are being incorporated into the result each time the unfolding is iterated. There is a tension, then, between minimizing the dependence on the prior, and minimizing the statistical uncertainty due to the unfolding-- this is the topic of Section~\ref{chapter:color:unfolding:optimization}.

	There are a few remaining details which are important to consider when performing an unfolding in practice. The response matrix $\mathbf{A}$ is by definition filled using events which pass both the truth-level and reco-level selection-- but there are also events which pass only one of the two selections. Fiducial factors $f_{i} = \frac{N^{\rm truth\;\wedge\;reco}_{i}}{N^{\rm reco}_{i}}$ are defined to measure the rate at which events which pass the reconstructed selection do not pass the truth selection. Simiarly, correction factors $c_{i} = \frac{N^{\rm reco\;\wedge\;truth}_{i}}{N^{\rm truth}_{i}}$ define the rate at which events pass the truth selection but not the reconstructed selection. Together, these correct the reconstructed fiducial selection to the truth-level fiducial selection.

	Now, defining $\mathbf{d}$ as the original data distribution with $n$ bins, and $d_i$ as the element in bin $i$; $\mathbf{b}$ as the distribution of expected background events; $\mathbf{y}$ as the signal distribution; and $\mathbf{x}$ as the unfolded distribution itself, we can say:
%
\begin{equation}
\begin{array} {rcl}
  y_i & = & (d_i - b_i) \cdot f_i \\
    x_i & = & (\boldsymbol{\theta} \cdot \mathbf{y})_i\,/\,c_i
    \end{array}
\end{equation}
%
	where $\mathbf{\theta}$ is our familiar friend constructed via $\mathbf{A}$ and the prior as discussed earlier. Finally, it should be noted that in this analysis we present normalized distributions of the unfolded quantity $Z$, and so the unfolded result in a bin $j$ is presented as:
%
\begin{equation}
  \frac{1}{\sigma} \frac{d\sigma}{dZ_j} = \frac{1}{\Delta Z_j N} \cdot x_j \ ,
  %\frac{\theta_{ij}}{c_j} \cdot f_i \cdot (d_i - b_i) \ ,
\end{equation}
%
where $\Delta Z_j$ is the width of the bin $j$ and $N$ is the normalization of the unfolded histogram.

Does this technique work? One simple way to check is to unfold simulation with itself, as shown for many iterations in Figure~\ref{fig:color:unfolding:simpletest}. Indeed, after one iteration the unfolded distribution matches the truth distribution, and additional uncertainties only serve to increase the statistical uncertainty (plotted as a vertical bar). Note that in general our prior will be the \PowPythia\ $t\bar{t}$ sample: we assume (to start, anyway) that the truth color flow is that of a singlet, and that \Pythia\ well describes the showering.

\begin{figure}[htb]
  \begin{center}
  \includegraphics[width=.45\linewidth]{cf_int/unfolding/Iterations_Muons_PullAllCaloAxis_PowhegPythia}
  \includegraphics[width=.45\linewidth]{cf_int/unfolding/Iterations_Muons_PullChargedTrackAxis_PowhegPythia}
  \caption[]{The results of unfolding \PowPythia\ events using the same
    \PowPythia\ events for various numbers of iterations. The vertical lines correspond to the statistical uncertainty.  The all-particle
    and charged-particle pull angles are shown at detector level and truth-hadron
    level in dark and light blue respectively.}
  \label{fig:color:unfolding:simpletest}
  \end{center}
\end{figure}
%The default number of iterations used, 15 for the all-particle pull and 4 for the charged-particle pull,are highlighted in orange.


	\subsection{Optimization}
	\label{chapter:color:unfolding:optimization}

	\subsubsection{Range of Optimization}

	To define the final analysis, several choices still need to be made. In particular, the \textit{binning}, \textit{pull vector magnitude cut}, and \textit{number of iterations} need to be optimized separetly for the all particles and charged particles measurements.

	The \textbf{binning} is a seemingly trivial choice-- we naturally prefer a fine binning, especially given that we have a fair amount of $t\bar{t}$ events to unfold. However, we also want a diagonal response matrix, so that the unfolding has to do less work and is less prone to flucutations. Unfortunately, the utility of additional bins is somewhat diluted by the very broad resolution of the pull angle, which is indeed on the same order as the bounded size of the observable itself. On the other hand, the charged particles measurement is expected to allow more bins because of its improved resolution.

	The \textbf{pull vector magnitude cut} is a simple tradeoff between resolution and statistics: can we afford to throw away events we think are less well measured, at the price of increasing the statistical uncertainty?

	Finally, the \textbf{number of iterations} is directly related to the iterative unfolding approach. We know already that the sensitivity to the prior decreases  with more iterations, but the statistical uncertainty increases.

	\subsubsection{Optimization Metric}

	It is also important to consider exactly what the metric for optimization is. One reasonable choice is the total uncertainty on the measurement, assessed using a subset of the most important uncertainties on the analysis. The effects of each of these on the optimization is described below.

	The \textbf{Color Flow Model} compares the unfolding using the nominal \PowPythia\ $t\bar{t}$ MC and the flipped, color octet \PowPythia. This is a direct test of the sensitivity of the prior, as these have the maximally different pull angle distribution.

	The \textbf{Shower/Hadronization Model} compares the unfolding using a flipped \PowPythia\ sample with a flipped \PowHerwig sample: this is another direct assessment of the effect of our prior choice of showering model. 

	The \textbf{Method Non-Closure} is a systematic assigned for the Bayseian unfolding's non-closure: this is described in more detail in Section~\ref{chapter:color:unfolding:uncertainties}.

	The \textbf{Data Statistical Uncertainty} is the propagated statistical uncertainty on the input to the unfolding: more iterations, more cuts on the pull vector magnitude, and more bins are expected to increase this.

	Likewise, the \textbf{MC Statistical Uncertainty} is the propagated statistical uncertainty on the response matrix. This is also sensitive to binning choices and additional cuts on the fiducial volume.

	\subsubsection{Optimization Results}

	336 different configurations are tested for the charged pull distribution; 784 configurations are tested for the all particles pull. The results are summarized in Figure~\ref{fig:color:unfolding:optimizationsummary}, where each $x$-axis point is a different configuration of the optimization. The general trend of both figures is due to the increasing of the cut on the pull vector magnitude; the high frequency oscillations are due to repeated scans of the number of iterations. Figure~\ref{fig:color:unfolding:optimizationsummarywinners} shows the uncertainty due to each effect for the optimal configuration.

%
\begin{figure}[h!]
  \begin{center}
    \includegraphics[width=.45\linewidth]{cf_int/unfolding/optimization/all_summary}
    \includegraphics[width=.45\linewidth]{cf_int/unfolding/optimization/summary}
    \caption{The sum in quadrature of the fractional uncertainty due to the color flow model, the shower/hadronization model, the method non-closure, and the data and MC statistics, for the all particles pull angle on the left and the charged particles pull angle on the right.  The uncertainty is normalized by the number of bins.  Electron and muon channels combined.}
    \label{fig:color:unfolding:optimizationsummary}
  \end{center}
\end{figure}
%

	From this study, we can extract the optimal parameters:
	\begin{itemize}
	\item 3 bins for the all particles measurement, and 4 bins for the charged particles measurement.
	\item A cut on the pull vector magnitude for the all particles case is slightly preferred; no cut is preferred for charged particles. Because this optimizaiton is so shallow, and the cut will introduce additional complications with the JES and JER uncertainties, it is decided to apply no cut in both measurements.
	\item 4 iterations for the charged pull angle, and 15 for the all particles angle.
	\end{itemize}


%
\begin{figure}[h!]
  \begin{center}
    \includegraphics[width=.45\linewidth]{cf_int/unfolding/optimization/all_498.pdf}
    \includegraphics[width=.45\linewidth]{cf_int/unfolding/optimization/49.pdf}
    \caption{The fractional uncertainty due to the main systematic uncertainties for the optimization scan parameters with the smallest bin-averaged uncertainty.  Electron and muon channels combined.}
    \label{fig:color:unfolding:optimizationsummarywinners}
  \end{center}
\end{figure}
%

	One particularly useful way to understand the physics motivation for this selection is presented in Figure~\ref{fig:color:unfolding:optimization_iter}. Here, the fractional uncertainty on the unfolding in each bin is shown as a function of the number of iterations. It is clear that there is a minimum in the total uncertainty, and that it is mostly driven by the minimization of the color flow model uncertainty: i.e., the prior distribution. 

	\editnote{Discussion on boundedness? Probably not necessary.}
%
\begin{figure}[h!]
  \begin{center}
    \includegraphics[width=0.45\textwidth]
      {cf_int/unfolding/niterations/ItUncert_Muons_PullAllCaloAxis_PowhegPythia}
    \includegraphics[width=0.45\textwidth]
      {cf_int/unfolding/niterations/ItUncert_Muons_PullChargedTrackAxis_PowhegPythia}
    \caption{Fractional uncertainties due to statistics, generator modelling
      and the color flow model on the two pull angles considered.}
      %\textcolor{red}{Double check non-closure uncertainties.}}
    \label{fig:color:unfolding:optimization_iter}
  \end{center}
\end{figure}


	\subsection{Unfolding Inputs}

	Now that we have the binning and final selections optimized, we can show the various unfolding factors derived in MC: the response matrix $\mathbf{A}$, the fiducial factors $f_i$, and the correction factors $c_i$. All of these are shown for \PowPythia $t\bar{t}$, the nominal MC used for the unfolding.

	Figure~\ref{fig:color:unfolding:nominal_response} shows the response matrices separately for electron and muon channels, for both charged and all particles measurements. The electron and muon channels being so similar will motivate us to later combine the channels and unfold together. The non-diagonal nature of the responses matrices is immediately apparent: the resolution is quite poor, but the charged particles resolution is slightly better.

\begin{figure}
  \includegraphics[width=0.45\textwidth]{cf_int/unfolding/responses/Electrons_PullAllCaloAxis_PowhegPythia_response_matrix}
  \includegraphics[width=0.45\textwidth]{cf_int/unfolding/responses/Electrons_PullChargedTrackAxis_PowhegPythia_response_matrix} \\
    \includegraphics[width=0.45\textwidth]{cf_int/unfolding/responses/Muons_PullAllCaloAxis_PowhegPythia_response_matrix}
    \includegraphics[width=0.45\textwidth]{cf_int/unfolding/responses/Muons_PullChargedTrackAxis_PowhegPythia_response_matrix}
    \caption{Nominal response matrices used in this analysis. Each bin is
      normalised such that each row equals 100\%.}
      \label{fig:color:unfolding:nominal_response}
\end{figure}

	Figure~\ref{fig:color:unfolding:fiducial_factors} shows the fiducial factors for several generators, and Figure~\ref{fig:color:unfolding:correction_factors} shows the correction factors. These are all approximately consistent amongst the generators.
%
\begin{figure}
  \includegraphics[width=0.45\textwidth]{cf_int/unfolding/fiducial_factors/Electrons_PullAllCaloAxis_Fiducial}
  \includegraphics[width=0.45\textwidth]{cf_int/unfolding/fiducial_factors/Electrons_PullChargedTrackAxis_Fiducial} \\
    \includegraphics[width=0.45\textwidth]{cf_int/unfolding/fiducial_factors/Muons_PullAllCaloAxis_Fiducial}
    \includegraphics[width=0.45\textwidth]{cf_int/unfolding/fiducial_factors/Muons_PullChargedTrackAxis_Fiducial}
    \caption{Fiducial factors obtained for three different generators.
      The fidcuial factors change by less than one per-cent with respect
      to pull angle, and are consistent between generators.}
      \label{fig:color:unfolding:fiducial_factors}
\end{figure}
%
\begin{figure}
  \includegraphics[width=0.45\textwidth]{cf_int/unfolding/correction_factors/Electrons_PullAllCaloAxis_RecoEff}
  \includegraphics[width=0.45\textwidth]{cf_int/unfolding/correction_factors/Electrons_PullChargedTrackAxis_RecoEff} \\
    \includegraphics[width=0.45\textwidth]{cf_int/unfolding/correction_factors/Muons_PullAllCaloAxis_RecoEff}
    \includegraphics[width=0.45\textwidth]{cf_int/unfolding/correction_factors/Muons_PullChargedTrackAxis_RecoEff}
    \caption{Correction factors obtained for three different generators.
      The fiducial factors change by less than one per-cent with respect
      to pull angle, and are consistent between generators.}
      \label{fig:color:unfolding:correction_factors}
\end{figure}



	\subsection{Combining Lepton Channels}
	We have previously seen that the response matrices for the muon and electron channels are nearly identical, in Figure~\ref{fig:color:unfolding:nominal_response}. This motivates the combination of the channels and the simultaneous unfolding of the entire distribution, as this is the easiest way by far to combine the result and benefit from the increase in statistics. To test whether this is actually appropriate, Figure~\ref{fig:color::unfolding:response_channel_comp} compares the unfolded results of each channel separately to the combined result. These are clearly all compatible, and so going forward the results will be shown for the combined analysis.

\begin{figure}
  \includegraphics[width=0.45\textwidth]{cf_int/unfolding/responses/channel_ratio_PullAllCaloAxis_PowhegPythia_response_matrix}
  \includegraphics[width=0.45\textwidth]{cf_int/unfolding/responses/channel_ratio_PullChargedTrackAxis_PowhegPythia_response_matrix}
  \caption{The ratio of the muon channel over electron channel response matrices
    for the all-particle and charged-particle pull angles.}
  \label{fig:color::unfolding:response_channel_comp}
\end{figure}

	\subsection{Unfolding Uncertainties}
	\label{chapter:color:unfolding:uncertainties}

	\subsubsection{Unfolding Non-closure}

	One final uncertainty has so far not been discussed: this is the uncertainty most intimately related to the unfolding, and measures the non-closure of the technique. A standard ATLAS procedure is used to assess this, in order to consider possible effects in the data which could bias the unfolding itself. First, the reconstructed MC is reweighted to match the data more closely using a first-order polynomial: this is shown in Figure~\ref{fig:color:unfolding:datamc_ratio}. The reweighted sample (mimimicing the data) is then unfolded using the nominal MC unfolding matrix: the resulting unfolded distribution is compared to the reweighted truth level distribution. If the reweighting is not pathological, it should have affected both the truth and reconstructed distributions similarly, and the difference should be small. In genreal, it is a few percent.

\begin{figure}[h!]
  \includegraphics[width=.45\linewidth]{cf_int/unfolding/nonclosure/truth_ratio_Muons_J1J2}
  \includegraphics[width=.45\linewidth]{cf_int/unfolding/nonclosure/truth_ratio_Muons_J1J2q_taxis}
  \caption{Data/MC ratios for the two pull angles. The ratio is fitted with a
    straight line (shown in magenta).}
  \label{fig:color:unfolding:datamc_ratio}
\end{figure}

\begin{figure}[h!]
  \includegraphics[width=.45\linewidth]{cf_int/unfolding/reweighting/Iterations_Muons_PullAllCaloAxis_PowhegPythiaReweightedTruth}
  \includegraphics[width=.45\linewidth]{cf_int/unfolding/reweighting/Iterations_Muons_PullChargedTrackAxis_PowhegPythiaReweightedTruth}
  \caption{The results of unfolding a reweighted (R) \PowPythia\ sample using
    the nominal \PowPythia\ sample for varying number of iterations.
    The uncertainty due to non-closure is defined as the difference
    between the truth-level reweighted MC and the unfolded reweighted MC.}
  \label{fig:color:unfolding:nonclosure}
\end{figure}


\subsubsection{Uncertainty Summaries}

	
	Before we present the final results, it is important to understand the main sources of uncertainty. Figure~\ref{fig:color:unfolding:systs_combined} shows a breakdown of the dominant uncertainties in each bin of both analyses. The subdominant uncertainties are combined into the ``other'' grouping in this figure; these are broken down in Figure~\ref{fig:color:unfolding:systs_small}. Many of these, such as the lepton scale, are related to the experimental acceptance and have vanishingly small effects on the final result. I NEED TO MENTION THEORY BREAKDOWN Finally, Figure~\ref{fig:color:unfolding:uncert_chart} shows a breakdown of the dominant sources of uncertainty in just the first bin of each analysis, showing the size of each uncertainty more clearly. 


\begin{figure}[htb]
  \includegraphics[width=.45\linewidth]{cf_int/unfolding/systematics/Systematics_All_PullAllCaloAxis}
  \includegraphics[width=.45\linewidth]{cf_int/unfolding/systematics/Systematics_All_PullChargedTrackAxis} \\
  \caption{Breakdowns of dominant systematic uncertainties affecting the all
    particles pull angle and the charged particles pull angle distributions for
    the combination of the electron and muon channels respectively. Sub-dominant systematics
    (those which do not have one bin in which the uncertainty is larger than
    0.5\%) are summed in quadrature in the band labeled other
    and are shown in more detail
    in Figure \ref{fig:color:unfolding:systs_small}}.
  \label{fig:color:unfolding:systs_combined}
\end{figure}



\begin{figure}[htb]
  \includegraphics[width=.99\linewidth]{cf_int/unfolding/systematics/uncerts_caxis_binning.pdf} \\
  \includegraphics[width=.99\linewidth]{cf_int/unfolding/systematics/uncerts_taxis_binning.pdf} \\
  \caption{A breakdown of the relative uncertainty due to the sub-leading systematic uncertainties affecting the (a) all particles pull angle and (b) the charged particles pull angle.  Electron and muon channels combined.  The labels are defined as JER = jet energy resolution, JES up/dn = one component JES (for illustration purposes only), Single top DS = compare DS and DR schemes, light/c/b scale up/dn = $b$-tag scale factor uncertainties, $W$+jets norm X up/dn = $W$+jets scale factor uncertainties, lumi up/dn = luminosity uncertainty, CES = cluster energy scale, Multijets XYZ = uncertainties associated with the matrix method, mms/mid = muon uncertainties, eer/ees = electron uncertainties, res/sc soft = MET soft term uncertainties, \_UP/\_DN = JES component uncertainties.}
  \label{fig:color:unfolding:systs_small}
\end{figure}



% theory here


\begin{figure}[htbp]
  \centering
    \includegraphics[width=0.8\textwidth]{paper/uncert_chart.pdf}
  \caption{A chart showing the size of the systematic uncertainties, for the all-particles and charged particles measurement, in the first bin of each measurement.}
  \label{fig:color:unfolding:uncert_chart}
\end{figure}






	\subsection{Results}

	\subsection{Hypothesis Testing}
		